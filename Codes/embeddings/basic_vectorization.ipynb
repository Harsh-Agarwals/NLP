{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd10088d",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "**Vectorization are an important part in text processing before passing it to a model.** We know that a computer cannot understand words, so it is first converted to a number, that is then passed through a Neural Network to train parameters of the model.\n",
    "\n",
    "Over time, vectorization have evolved from simplest statics vectorization methods like one-hot-code vectorization and bag-of-words to neural network based, trainable and dynamic vectorization techniques like Word2Vec and contextual/positional encodings.\n",
    "\n",
    "In this notebook we will explore simple vectorization techniques, which are:\n",
    "- OHE\n",
    "- Bag of words\n",
    "- TF-IDF\n",
    "\n",
    "We will build them from scratch and will also use NLTK/Gensim for getting vectorization vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758c440",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa94fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/silvercule/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import kagglehub\n",
    "import os\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20fd1ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/harshagarwal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c626b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/harshagarwal/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import  sent_tokenize, word_tokenize\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c411d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/harshagarwal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ea46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f66261b",
   "metadata": {},
   "source": [
    "## Implementing text preprocessing (tokenization) as performed in *tokenization/basic_tokenizers* notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a79ad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>patterns</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>anyone ola hey hi howdy konnichiwa guten tag h...</td>\n",
       "      <td>hello tell feel today hi bring today hi feel t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>great wake good start day great start day good...</td>\n",
       "      <td>good morn hope good night sleep feel today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>nice day good start day good day good afternoo...</td>\n",
       "      <td>good afternoon day go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evening</td>\n",
       "      <td>nice day nice morning good night good morning ...</td>\n",
       "      <td>good even day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>night</td>\n",
       "      <td>good even good night nice nice day good night ...</td>\n",
       "      <td>good night get proper sleep good night sweet d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fact28</td>\n",
       "      <td>concern mental health im worry mental health i...</td>\n",
       "      <td>import thing talk someon trust might friend co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>fact29</td>\n",
       "      <td>sure im well im feel well know im well know po...</td>\n",
       "      <td>belief thought feel behaviour signific impact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>fact30</td>\n",
       "      <td>keep touch people stay touch friends do mainta...</td>\n",
       "      <td>lot peopl alon right dont lone togeth think di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>fact31</td>\n",
       "      <td>difference stress anxiety stress anxiety diffe...</td>\n",
       "      <td>stress anxieti often use interchang overlap st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fact32</td>\n",
       "      <td>differences sadness depression depression sadn...</td>\n",
       "      <td>sad normal reaction loss disappoint problem di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag                                           patterns  \\\n",
       "0    greeting  anyone ola hey hi howdy konnichiwa guten tag h...   \n",
       "1     morning  great wake good start day great start day good...   \n",
       "2   afternoon  nice day good start day good day good afternoo...   \n",
       "3     evening  nice day nice morning good night good morning ...   \n",
       "4       night  good even good night nice nice day good night ...   \n",
       "..        ...                                                ...   \n",
       "75     fact28  concern mental health im worry mental health i...   \n",
       "76     fact29  sure im well im feel well know im well know po...   \n",
       "77     fact30  keep touch people stay touch friends do mainta...   \n",
       "78     fact31  difference stress anxiety stress anxiety diffe...   \n",
       "79     fact32  differences sadness depression depression sadn...   \n",
       "\n",
       "                                            responses  \n",
       "0   hello tell feel today hi bring today hi feel t...  \n",
       "1          good morn hope good night sleep feel today  \n",
       "2                               good afternoon day go  \n",
       "3                                       good even day  \n",
       "4   good night get proper sleep good night sweet d...  \n",
       "..                                                ...  \n",
       "75  import thing talk someon trust might friend co...  \n",
       "76  belief thought feel behaviour signific impact ...  \n",
       "77  lot peopl alon right dont lone togeth think di...  \n",
       "78  stress anxieti often use interchang overlap st...  \n",
       "79  sad normal reaction loss disappoint problem di...  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"selimkhaled50/new-data\")\n",
    "text = pd.read_json(os.path.join(path, os.listdir(path)[0]))\n",
    "\n",
    "text['tag'] = text.intents.apply(lambda x: x['tag'])\n",
    "text['patterns'] = text.intents.apply(lambda x: ' '.join(x['patterns']))\n",
    "text['responses'] = text.intents.apply(lambda x: ' '.join(x['responses']))\n",
    "\n",
    "text.drop(columns=['intents'], inplace=True)\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    return ''.join(i for i in list(text) if i not in string.punctuation)\n",
    "\n",
    "texts = text.copy()\n",
    "texts['patterns'] = texts.patterns.apply(lambda x: remove_punctuations(x))\n",
    "texts['responses'] = texts.responses.apply(lambda x: remove_punctuations(x))\n",
    "texts['tag'] = texts.tag.apply(lambda x: remove_punctuations(x))\n",
    "\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "texts['patterns'] = texts.patterns.apply(lambda x: convert_to_lowercase(x))\n",
    "texts['responses'] = texts.responses.apply(lambda x: convert_to_lowercase(x))\n",
    "texts['tag'] = texts.tag.apply(lambda x: convert_to_lowercase(x))\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stopwords])\n",
    "\n",
    "texts['patterns'] = texts.patterns.apply(lambda x: remove_stopwords(x))\n",
    "texts['responses'] = texts.responses.apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lematize_text_n(text):\n",
    "    return ' '.join(lemmatizer.lemmatize(word, pos=\"n\") for word in text.split())\n",
    "\n",
    "def lematize_text_v(text):\n",
    "    return ' '.join(lemmatizer.lemmatize(word, pos=\"v\") for word in text.split())\n",
    "\n",
    "texts['patterns'] = texts.patterns.apply(lambda x: lematize_text_v(x))\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    return \" \".join(stemmer.stem(word) for word in text.split())\n",
    "\n",
    "texts['responses'] = texts.responses.apply(lambda x: stem_text(x))\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d653b1f",
   "metadata": {},
   "source": [
    "Now we have the pre-processed text, and we need to convert this into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "933fc7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('anyone ola hey hi howdy konnichiwa guten tag hi hola hey bonjour hello',\n",
       " 'Is anyone there? Ola Hey there Hi there Howdy Konnichiwa Guten tag Hi Hola Hey Bonjour Hello')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts['patterns'][0], text['patterns'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4d0dccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hello tell feel today hi bring today hi feel today great see feel current hello glad see your back what go world right',\n",
       " \"Hello there. Tell me how are you feeling today? Hi there. What brings you here today? Hi there. How are you feeling today? Great to see you. How do you feel currently? Hello there. Glad to see you're back. What's going on in your world right now?\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts['responses'][0], text['responses'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40d0d0",
   "metadata": {},
   "source": [
    "## One Hot Code Embedding\n",
    "\n",
    "In one hot code encoding, we first make a vocabulary, or choose an already made vocabulary. Then we make a vector with the same size as our chosen vocabulary. Now for every word in our corpus, we make a vector with that word corresponding to 1 and other words corresponding to 0 in our vector.\n",
    "\n",
    "Let's make a simple vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "668a1ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(754,\n",
       " ['1',\n",
       "  '10',\n",
       "  '1318',\n",
       "  '1524',\n",
       "  '18',\n",
       "  '2',\n",
       "  '24',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '7090',\n",
       "  '75',\n",
       "  '8',\n",
       "  '9',\n",
       "  '9152987821',\n",
       "  'abil',\n",
       "  'abl',\n",
       "  'abus',\n",
       "  'access',\n",
       "  'accord',\n",
       "  'ach',\n",
       "  'act',\n",
       "  'activ',\n",
       "  'actual',\n",
       "  'addit',\n",
       "  'adolesc',\n",
       "  'adult',\n",
       "  'advic',\n",
       "  'advis',\n",
       "  'affect',\n",
       "  'afraid',\n",
       "  'afternoon',\n",
       "  'age',\n",
       "  'agent',\n",
       "  'aggress',\n",
       "  'ai',\n",
       "  'aid',\n",
       "  'aim',\n",
       "  'alcohol',\n",
       "  'allevi',\n",
       "  'alon',\n",
       "  'along',\n",
       "  'alright',\n",
       "  'also',\n",
       "  'altern',\n",
       "  'although',\n",
       "  'alway',\n",
       "  'america',\n",
       "  'andor',\n",
       "  'anger',\n",
       "  'anoth',\n",
       "  'answer',\n",
       "  'anxieti',\n",
       "  'anyon',\n",
       "  'anyth',\n",
       "  'anyway',\n",
       "  'appetit',\n",
       "  'appli',\n",
       "  'approach',\n",
       "  'appropri',\n",
       "  'area',\n",
       "  'arent',\n",
       "  'aris',\n",
       "  'around',\n",
       "  'ask',\n",
       "  'aspect',\n",
       "  'assist',\n",
       "  'assit',\n",
       "  'associ',\n",
       "  'assum',\n",
       "  'attent',\n",
       "  'attitud',\n",
       "  'author',\n",
       "  'avail',\n",
       "  'avoid',\n",
       "  'aw',\n",
       "  'awar',\n",
       "  'away',\n",
       "  'back',\n",
       "  'background',\n",
       "  'base',\n",
       "  'becom',\n",
       "  'begin',\n",
       "  'behav',\n",
       "  'behavior',\n",
       "  'behaviour',\n",
       "  'behind',\n",
       "  'belief',\n",
       "  'benefici',\n",
       "  'benefit',\n",
       "  'best',\n",
       "  'big',\n",
       "  'biolog',\n",
       "  'bipolar',\n",
       "  'bluea',\n",
       "  'brain',\n",
       "  'break',\n",
       "  'breath',\n",
       "  'bring',\n",
       "  'broad',\n",
       "  'build',\n",
       "  'bye',\n",
       "  'call',\n",
       "  'cannot',\n",
       "  'cant',\n",
       "  'capac',\n",
       "  'care',\n",
       "  'caretak',\n",
       "  'case',\n",
       "  'caus',\n",
       "  'certain',\n",
       "  'challeng',\n",
       "  'chang',\n",
       "  'charact',\n",
       "  'characteris',\n",
       "  'chat',\n",
       "  'check',\n",
       "  'child',\n",
       "  'children',\n",
       "  'childrenâ€™',\n",
       "  'childã¢â‚¬â„¢',\n",
       "  'choic',\n",
       "  'chosen',\n",
       "  'circl',\n",
       "  'citi',\n",
       "  'clergi',\n",
       "  'clinic',\n",
       "  'close',\n",
       "  'coach',\n",
       "  'colleagu',\n",
       "  'combin',\n",
       "  'come',\n",
       "  'comfort',\n",
       "  'common',\n",
       "  'commun',\n",
       "  'complaint',\n",
       "  'complementari',\n",
       "  'comput',\n",
       "  'concentr',\n",
       "  'concern',\n",
       "  'condit',\n",
       "  'condol',\n",
       "  'confus',\n",
       "  'connect',\n",
       "  'consid',\n",
       "  'construct',\n",
       "  'consum',\n",
       "  'contact',\n",
       "  'continuum',\n",
       "  'contribut',\n",
       "  'control',\n",
       "  'convers',\n",
       "  'coordin',\n",
       "  'cope',\n",
       "  'could',\n",
       "  'counsel',\n",
       "  'counselor',\n",
       "  'countri',\n",
       "  'cours',\n",
       "  'cowork',\n",
       "  'creat',\n",
       "  'critic',\n",
       "  'crucial',\n",
       "  'current',\n",
       "  'daili',\n",
       "  'damag',\n",
       "  'danger',\n",
       "  'dataset',\n",
       "  'day',\n",
       "  'death',\n",
       "  'decis',\n",
       "  'deep',\n",
       "  'deepli',\n",
       "  'defi',\n",
       "  'deficithyperact',\n",
       "  'definit',\n",
       "  'delus',\n",
       "  'denial',\n",
       "  'depend',\n",
       "  'depress',\n",
       "  'design',\n",
       "  'despit',\n",
       "  'determin',\n",
       "  'develop',\n",
       "  'diabet',\n",
       "  'diagnos',\n",
       "  'diagnosi',\n",
       "  'didnt',\n",
       "  'differ',\n",
       "  'difficult',\n",
       "  'diminish',\n",
       "  'direct',\n",
       "  'disabl',\n",
       "  'disappear',\n",
       "  'disappoint',\n",
       "  'discrimin',\n",
       "  'discuss',\n",
       "  'disobedi',\n",
       "  'disord',\n",
       "  'disrupt',\n",
       "  'distanc',\n",
       "  'distress',\n",
       "  'disturb',\n",
       "  'doesnt',\n",
       "  'done',\n",
       "  'dont',\n",
       "  'dose',\n",
       "  'dramat',\n",
       "  'dream',\n",
       "  'drink',\n",
       "  'drug',\n",
       "  'due',\n",
       "  'duh',\n",
       "  'earli',\n",
       "  'easi',\n",
       "  'eat',\n",
       "  'educ',\n",
       "  'effect',\n",
       "  'effort',\n",
       "  'elabor',\n",
       "  'els',\n",
       "  'elucid',\n",
       "  'emot',\n",
       "  'encourag',\n",
       "  'end',\n",
       "  'energi',\n",
       "  'engag',\n",
       "  'enhanc',\n",
       "  'enjoy',\n",
       "  'especi',\n",
       "  'essenti',\n",
       "  'estim',\n",
       "  'ethnic',\n",
       "  'even',\n",
       "  'event',\n",
       "  'everi',\n",
       "  'everyday',\n",
       "  'everyon',\n",
       "  'everywher',\n",
       "  'exam',\n",
       "  'examin',\n",
       "  'exampl',\n",
       "  'excess',\n",
       "  'exercis',\n",
       "  'exhal',\n",
       "  'exhibit',\n",
       "  'experi',\n",
       "  'experienc',\n",
       "  'expertis',\n",
       "  'express',\n",
       "  'extern',\n",
       "  'extra',\n",
       "  'extrem',\n",
       "  'face',\n",
       "  'fact',\n",
       "  'fairli',\n",
       "  'fall',\n",
       "  'famili',\n",
       "  'fear',\n",
       "  'feel',\n",
       "  'femal',\n",
       "  'fight',\n",
       "  'figur',\n",
       "  'find',\n",
       "  'first',\n",
       "  'fit',\n",
       "  'flight',\n",
       "  'focu',\n",
       "  'focus',\n",
       "  'follow',\n",
       "  'food',\n",
       "  'forgiv',\n",
       "  'form',\n",
       "  'forward',\n",
       "  'found',\n",
       "  'free',\n",
       "  'freez',\n",
       "  'frequent',\n",
       "  'friend',\n",
       "  'friendship',\n",
       "  'fruit',\n",
       "  'fulfil',\n",
       "  'fulli',\n",
       "  'function',\n",
       "  'gain',\n",
       "  'gather',\n",
       "  'geat',\n",
       "  'gender',\n",
       "  'gener',\n",
       "  'gentli',\n",
       "  'get',\n",
       "  'give',\n",
       "  'glad',\n",
       "  'go',\n",
       "  'goe',\n",
       "  'gonna',\n",
       "  'good',\n",
       "  'gp',\n",
       "  'grade',\n",
       "  'great',\n",
       "  'grief',\n",
       "  'group',\n",
       "  'guilti',\n",
       "  'habit',\n",
       "  'hallucin',\n",
       "  'hand',\n",
       "  'handl',\n",
       "  'happen',\n",
       "  'happi',\n",
       "  'hard',\n",
       "  'heal',\n",
       "  'health',\n",
       "  'healthcar',\n",
       "  'hear',\n",
       "  'heard',\n",
       "  'hello',\n",
       "  'help',\n",
       "  'hesit',\n",
       "  'hi',\n",
       "  'high',\n",
       "  'highli',\n",
       "  'hope',\n",
       "  'hopeless',\n",
       "  'hospit',\n",
       "  'howev',\n",
       "  'human',\n",
       "  'hurt',\n",
       "  'hydrat',\n",
       "  'hyperact',\n",
       "  'id',\n",
       "  'identif',\n",
       "  'identifi',\n",
       "  'ill',\n",
       "  'im',\n",
       "  'impact',\n",
       "  'impair',\n",
       "  'import',\n",
       "  'improv',\n",
       "  'inabl',\n",
       "  'includ',\n",
       "  'incom',\n",
       "  'increas',\n",
       "  'independ',\n",
       "  'indian',\n",
       "  'indic',\n",
       "  'individu',\n",
       "  'inform',\n",
       "  'inhal',\n",
       "  'instanc',\n",
       "  'insulin',\n",
       "  'intellig',\n",
       "  'intens',\n",
       "  'interchang',\n",
       "  'interest',\n",
       "  'interfer',\n",
       "  'involv',\n",
       "  'irregularli',\n",
       "  'irrit',\n",
       "  'isnt',\n",
       "  'isol',\n",
       "  'issu',\n",
       "  'itll',\n",
       "  'job',\n",
       "  'joke',\n",
       "  'journey',\n",
       "  'judgement',\n",
       "  'keep',\n",
       "  'kind',\n",
       "  'know',\n",
       "  'known',\n",
       "  'languag',\n",
       "  'last',\n",
       "  'later',\n",
       "  'lead',\n",
       "  'learn',\n",
       "  'least',\n",
       "  'led',\n",
       "  'let',\n",
       "  'level',\n",
       "  'lie',\n",
       "  'life',\n",
       "  'lifetim',\n",
       "  'like',\n",
       "  'line',\n",
       "  'list',\n",
       "  'listen',\n",
       "  'littl',\n",
       "  'live',\n",
       "  'local',\n",
       "  'lone',\n",
       "  'loneli',\n",
       "  'long',\n",
       "  'longer',\n",
       "  'longlast',\n",
       "  'look',\n",
       "  'lose',\n",
       "  'loss',\n",
       "  'lost',\n",
       "  'lot',\n",
       "  'love',\n",
       "  'low',\n",
       "  'lower',\n",
       "  'made',\n",
       "  'mainli',\n",
       "  'maintain',\n",
       "  'major',\n",
       "  'make',\n",
       "  'manag',\n",
       "  'mani',\n",
       "  'mask',\n",
       "  'matter',\n",
       "  'may',\n",
       "  'mayb',\n",
       "  'meaning',\n",
       "  'measur',\n",
       "  'media',\n",
       "  'medic',\n",
       "  'medicin',\n",
       "  'medit',\n",
       "  'meet',\n",
       "  'member',\n",
       "  'mental',\n",
       "  'met',\n",
       "  'might',\n",
       "  'mild',\n",
       "  'mimic',\n",
       "  'mind',\n",
       "  'mindlessli',\n",
       "  'minut',\n",
       "  'miss',\n",
       "  'momentari',\n",
       "  'monitor',\n",
       "  'mood',\n",
       "  'morn',\n",
       "  'move',\n",
       "  'much',\n",
       "  'multipl',\n",
       "  'mutual',\n",
       "  'name',\n",
       "  'natur',\n",
       "  'nearli',\n",
       "  'need',\n",
       "  'neg',\n",
       "  'network',\n",
       "  'neurolog',\n",
       "  'new',\n",
       "  'next',\n",
       "  'nice',\n",
       "  'night',\n",
       "  'nightmar',\n",
       "  'normal',\n",
       "  'nostril',\n",
       "  'note',\n",
       "  'noth',\n",
       "  'notic',\n",
       "  'nutrit',\n",
       "  'obviou',\n",
       "  'occup',\n",
       "  'occur',\n",
       "  'offend',\n",
       "  'offer',\n",
       "  'often',\n",
       "  'oh',\n",
       "  'ok',\n",
       "  'okay',\n",
       "  'old',\n",
       "  'older',\n",
       "  'one',\n",
       "  'onlin',\n",
       "  'open',\n",
       "  'opinion',\n",
       "  'opportun',\n",
       "  'option',\n",
       "  'order',\n",
       "  'ordinari',\n",
       "  'organ',\n",
       "  'orient',\n",
       "  'other',\n",
       "  'outburst',\n",
       "  'overlap',\n",
       "  'overwhelm',\n",
       "  'pain',\n",
       "  'pancrea',\n",
       "  'pandem',\n",
       "  'pandora',\n",
       "  'parent',\n",
       "  'part',\n",
       "  'particular',\n",
       "  'particularli',\n",
       "  'path',\n",
       "  'peer',\n",
       "  'peerl',\n",
       "  'peopl',\n",
       "  'percent',\n",
       "  'perform',\n",
       "  'persist',\n",
       "  'person',\n",
       "  'perspect',\n",
       "  'phobia',\n",
       "  'phone',\n",
       "  'physic',\n",
       "  'physician',\n",
       "  'place',\n",
       "  'plan',\n",
       "  'pleas',\n",
       "  'pleasur',\n",
       "  'point',\n",
       "  'poor',\n",
       "  'popul',\n",
       "  'possibl',\n",
       "  'post',\n",
       "  'practic',\n",
       "  'practition',\n",
       "  'prefer',\n",
       "  'prepar',\n",
       "  'prescrib',\n",
       "  'pressur',\n",
       "  'preteen',\n",
       "  'preval',\n",
       "  'prevent',\n",
       "  'prime',\n",
       "  'proactiv',\n",
       "  'probabl',\n",
       "  'problem',\n",
       "  'problemsolv',\n",
       "  'process',\n",
       "  'produc',\n",
       "  'product',\n",
       "  'profession',\n",
       "  'program',\n",
       "  'proper',\n",
       "  'properti',\n",
       "  'provid',\n",
       "  'psychiatr',\n",
       "  'psychiatrist',\n",
       "  'psycholog',\n",
       "  'psychologist',\n",
       "  'put',\n",
       "  'qualiti',\n",
       "  'question',\n",
       "  'quickli',\n",
       "  'quit',\n",
       "  'rais',\n",
       "  'rang',\n",
       "  'rather',\n",
       "  'reach',\n",
       "  'react',\n",
       "  'reaction',\n",
       "  'readi',\n",
       "  'real',\n",
       "  'realis',\n",
       "  'realist',\n",
       "  'realiz',\n",
       "  'realli',\n",
       "  'reason',\n",
       "  'receiv',\n",
       "  'recent',\n",
       "  'recogn',\n",
       "  'recommend',\n",
       "  'recoveri',\n",
       "  'reduct',\n",
       "  'refer',\n",
       "  'referr',\n",
       "  'regard',\n",
       "  'regardless',\n",
       "  'regular',\n",
       "  'rehabilit',\n",
       "  'relat',\n",
       "  'relationship',\n",
       "  'relax',\n",
       "  'religion',\n",
       "  'rememb',\n",
       "  'repeat',\n",
       "  'report',\n",
       "  'requir',\n",
       "  'research',\n",
       "  'resili',\n",
       "  'resolv',\n",
       "  'resourc',\n",
       "  'respond',\n",
       "  'respons',\n",
       "  'rest',\n",
       "  'result',\n",
       "  'return',\n",
       "  'right',\n",
       "  'role',\n",
       "  'sad',\n",
       "  'satisfi',\n",
       "  'say',\n",
       "  'scari',\n",
       "  'schizophrenia',\n",
       "  'school',\n",
       "  'scroll',\n",
       "  'search',\n",
       "  'secondli',\n",
       "  'sed',\n",
       "  'see',\n",
       "  'seek',\n",
       "  'seem',\n",
       "  'selfhelp',\n",
       "  'selfimag',\n",
       "  'selfisol',\n",
       "  'sensat',\n",
       "  'seriou',\n",
       "  'servic',\n",
       "  'set',\n",
       "  'seven',\n",
       "  'sever',\n",
       "  'sexual',\n",
       "  'share',\n",
       "  'side',\n",
       "  'sign',\n",
       "  'signific',\n",
       "  'similar',\n",
       "  'similarli',\n",
       "  'simplest',\n",
       "  'sinc',\n",
       "  'situat',\n",
       "  'skill',\n",
       "  'skip',\n",
       "  'sleep',\n",
       "  'slowli',\n",
       "  'social',\n",
       "  'solut',\n",
       "  'solv',\n",
       "  'someon',\n",
       "  'someth',\n",
       "  'sometim',\n",
       "  'somewher',\n",
       "  'soon',\n",
       "  'sooner',\n",
       "  'sorri',\n",
       "  'sort',\n",
       "  'sound',\n",
       "  'sourc',\n",
       "  'speak',\n",
       "  'special',\n",
       "  'specialist',\n",
       "  'spectrum',\n",
       "  'stabil',\n",
       "  'start',\n",
       "  'state',\n",
       "  'statu',\n",
       "  'stay',\n",
       "  'steal',\n",
       "  'step',\n",
       "  'still',\n",
       "  'storm',\n",
       "  'strategi',\n",
       "  'stress',\n",
       "  'strike',\n",
       "  'strong',\n",
       "  'subsitut',\n",
       "  'substitut',\n",
       "  'success',\n",
       "  'suffer',\n",
       "  'suggest',\n",
       "  'suicid',\n",
       "  'support',\n",
       "  'suppos',\n",
       "  'sure',\n",
       "  'suscept',\n",
       "  'sweet',\n",
       "  'symptom',\n",
       "  'take',\n",
       "  'taken',\n",
       "  'talk',\n",
       "  'tantrum',\n",
       "  'team',\n",
       "  'techniqu',\n",
       "  'tell',\n",
       "  'temper',\n",
       "  'tend',\n",
       "  'term',\n",
       "  'test',\n",
       "  'text',\n",
       "  'that',\n",
       "  'therapeut',\n",
       "  'therapi',\n",
       "  'therapist',\n",
       "  'thing',\n",
       "  'think',\n",
       "  'thirdli',\n",
       "  'thought',\n",
       "  'threaten',\n",
       "  'throughout',\n",
       "  'time',\n",
       "  'tip',\n",
       "  'today',\n",
       "  'togeth',\n",
       "  'tool',\n",
       "  'touch',\n",
       "  'train',\n",
       "  'tranquil',\n",
       "  'treat',\n",
       "  'treatabl',\n",
       "  'treatment',\n",
       "  'tri',\n",
       "  'trust',\n",
       "  'two',\n",
       "  'type',\n",
       "  'typic',\n",
       "  'understand',\n",
       "  'unexplain',\n",
       "  'unicef',\n",
       "  'univers',\n",
       "  'unreason',\n",
       "  'us',\n",
       "  'use',\n",
       "  'usual',\n",
       "  'vari',\n",
       "  'varieti',\n",
       "  'variou',\n",
       "  'vent',\n",
       "  'video',\n",
       "  'vital',\n",
       "  'vulner',\n",
       "  'walk',\n",
       "  'wander',\n",
       "  'want',\n",
       "  'wasnt',\n",
       "  'way',\n",
       "  'week',\n",
       "  'weight',\n",
       "  'welcom',\n",
       "  'well',\n",
       "  'wellb',\n",
       "  'what',\n",
       "  'whenev',\n",
       "  'will',\n",
       "  'willpow',\n",
       "  'wish',\n",
       "  'withdraw',\n",
       "  'within',\n",
       "  'without',\n",
       "  'work',\n",
       "  'worker',\n",
       "  'world',\n",
       "  'worldwid',\n",
       "  'worri',\n",
       "  'wors',\n",
       "  'worthless',\n",
       "  'would',\n",
       "  'wouldnt',\n",
       "  'written',\n",
       "  'ye',\n",
       "  'year',\n",
       "  'youd',\n",
       "  'youll',\n",
       "  'young',\n",
       "  'younger',\n",
       "  'your'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(' '.join(texts['responses'].unique()).split(' '))))\n",
    "len(vocab), vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf9658",
   "metadata": {},
   "source": [
    "So, we have combined all our words and chose unique word of our words to make our vocabulary. Now our vocabulary vector will be of 754 size.\n",
    "\n",
    "Let's now form a basic vocabulary vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7bcfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((754,),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = np.zeros(shape=(len(vocab)))\n",
    "vector.shape, vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be807cf",
   "metadata": {},
   "source": [
    "So, we just made our basic vector. \n",
    "\n",
    "**Let's vectorize our first sentence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c94462b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello tell feel today hi bring today hi feel today great see feel current hello glad see your back what go world right'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts['responses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8171c2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23, 754),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], shape=(23, 754)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_0 = np.zeros((len(texts['responses'][0].split(\" \")), len(vector)))\n",
    "ohe_0.shape, ohe_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88396eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(23, 754))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "for word in texts['responses'][0].split(\" \"):\n",
    "    word_index = vocab.index(word)\n",
    "    ohe_0[i, word_index] = 1\n",
    "    i+=1\n",
    "\n",
    "ohe_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "000f1beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_0[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b6bc0",
   "metadata": {},
   "source": [
    "Now we have our vector ready for 1st sentence. Similarly we can do OHE for every sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76177f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = list(texts['responses'].unique())\n",
    "\n",
    "max_len = 0\n",
    "for i in responses:\n",
    "    if len(i.split(\" \"))>max_len:\n",
    "        max_len = len(i.split(\" \"))\n",
    "\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a80ec",
   "metadata": {},
   "source": [
    "### Now, let's decode the size of our input vectors.\n",
    "\n",
    "- First of all, it's length will be of the length of our data (80 here)\n",
    "- Then for each data point, we will have corresponding vector, having value 1 at the place of the value index in the vocabulary list.\n",
    "\n",
    "So, the overall size will be **(length of data x size of each vector x size of vocab)**\n",
    "\n",
    "Where size of each vector = maximum length of data among all data points. This is done ensuring all data points is of equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "513a9293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 204, 754)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_full = np.zeros((len(texts), max_len,len(vocab)))\n",
    "vectors_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8e94f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], shape=(80, 204, 754))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 0\n",
    "for i in responses:\n",
    "    for j, k in enumerate(i.split(\" \")):\n",
    "        index = vocab.index(k)\n",
    "        vectors_full[ind][j][index] = 1\n",
    "    ind+=1\n",
    "\n",
    "vectors_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b477488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.0), np.float64(0.0))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_full[0][0].sum(), vectors_full[0][200].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5889a7",
   "metadata": {},
   "source": [
    "So, we have done one-hot code encodings for our responses column of our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5111c61c",
   "metadata": {},
   "source": [
    "## Now let's build Bag-of-words\n",
    "\n",
    "### Intuition\n",
    "\n",
    "Bag of words is a vectorization algorithm based on the frequency count of every word. It does not consider order or the context of words in the sentences.\n",
    "\n",
    "From a vocabulary of unique words, bag of words vectorization is calculated. In a sentence, count of every word is calculated and accordingly assigned in vector of every sentence.\n",
    "\n",
    "The difference here in BOW from previous OHE is that OHE encode every sentence into vector of size (word count in sentence x vocabulary length), whereas here, encoding for every sentence is (1 x vocabulary length). We assign 1 vector to each sentence, of the size of our vocabulary, with entry for a word representing its count in that sentence.\n",
    "\n",
    "Eg. \"i love ice creams and i like summers\" => vocab: ['and', 'creams', 'i', 'ice', 'like', 'love', 'summers'] => BOW: [1, 1, 2, 1, 1, 1, 1]\n",
    "\n",
    "Let's build BOW from Scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f147895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330,\n",
       " ['able',\n",
       "  'absolutely',\n",
       "  'advice',\n",
       "  'affect',\n",
       "  'afraid',\n",
       "  'afternoon',\n",
       "  'alot',\n",
       "  'already',\n",
       "  'alright',\n",
       "  'anecdote',\n",
       "  'another',\n",
       "  'answer',\n",
       "  'anxiety',\n",
       "  'anxious',\n",
       "  'anymore',\n",
       "  'anyone',\n",
       "  'anything',\n",
       "  'appear',\n",
       "  'appreciate',\n",
       "  'approach',\n",
       "  'arrive',\n",
       "  'ask',\n",
       "  'assistance',\n",
       "  'au',\n",
       "  'available',\n",
       "  'aware',\n",
       "  'away',\n",
       "  'awful',\n",
       "  'bad',\n",
       "  'become',\n",
       "  'believe',\n",
       "  'better',\n",
       "  'bonjour',\n",
       "  'boyfriend',\n",
       "  'break',\n",
       "  'bring',\n",
       "  'brother',\n",
       "  'burn',\n",
       "  'bye',\n",
       "  'call',\n",
       "  'cannot',\n",
       "  'cant',\n",
       "  'cause',\n",
       "  'chance',\n",
       "  'cheerful',\n",
       "  'child',\n",
       "  'choices',\n",
       "  'commit',\n",
       "  'common',\n",
       "  'concern',\n",
       "  'connections',\n",
       "  'consider',\n",
       "  'contemplate',\n",
       "  'continue',\n",
       "  'control',\n",
       "  'correct',\n",
       "  'correctly',\n",
       "  'could',\n",
       "  'crazy',\n",
       "  'create',\n",
       "  'creator',\n",
       "  'crucial',\n",
       "  'cure',\n",
       "  'currently',\n",
       "  'dad',\n",
       "  'day',\n",
       "  'days',\n",
       "  'define',\n",
       "  'depress',\n",
       "  'depression',\n",
       "  'deserve',\n",
       "  'die',\n",
       "  'difference',\n",
       "  'differences',\n",
       "  'different',\n",
       "  'discuss',\n",
       "  'dislike',\n",
       "  'disorder',\n",
       "  'do',\n",
       "  'doesnt',\n",
       "  'dont',\n",
       "  'drug',\n",
       "  'due',\n",
       "  'dumb',\n",
       "  'else',\n",
       "  'empty',\n",
       "  'enjoy',\n",
       "  'enough',\n",
       "  'even',\n",
       "  'exams',\n",
       "  'exist',\n",
       "  'fact',\n",
       "  'family',\n",
       "  'fare',\n",
       "  'father',\n",
       "  'feel',\n",
       "  'financial',\n",
       "  'find',\n",
       "  'fine',\n",
       "  'focus',\n",
       "  'friend',\n",
       "  'friends',\n",
       "  'funnier',\n",
       "  'funny',\n",
       "  'get',\n",
       "  'girlfriend',\n",
       "  'give',\n",
       "  'go',\n",
       "  'good',\n",
       "  'goodbye',\n",
       "  'great',\n",
       "  'group',\n",
       "  'guess',\n",
       "  'guten',\n",
       "  'hand',\n",
       "  'happy',\n",
       "  'hate',\n",
       "  'havent',\n",
       "  'health',\n",
       "  'hello',\n",
       "  'help',\n",
       "  'helpful',\n",
       "  'hey',\n",
       "  'hi',\n",
       "  'hmmm',\n",
       "  'hola',\n",
       "  'howdy',\n",
       "  'id',\n",
       "  'ill',\n",
       "  'illness',\n",
       "  'illnesses',\n",
       "  'im',\n",
       "  'importance',\n",
       "  'important',\n",
       "  'indeed',\n",
       "  'information',\n",
       "  'inquire',\n",
       "  'insane',\n",
       "  'insominia',\n",
       "  'insomnia',\n",
       "  'interest',\n",
       "  'involve',\n",
       "  'isnt',\n",
       "  'issue',\n",
       "  'ive',\n",
       "  'joke',\n",
       "  'k',\n",
       "  'keep',\n",
       "  'kill',\n",
       "  'kind',\n",
       "  'kinds',\n",
       "  'know',\n",
       "  'konnichiwa',\n",
       "  'last',\n",
       "  'later',\n",
       "  'learn',\n",
       "  'let',\n",
       "  'like',\n",
       "  'live',\n",
       "  'locate',\n",
       "  'location',\n",
       "  'lonely',\n",
       "  'long',\n",
       "  'longer',\n",
       "  'look',\n",
       "  'lot',\n",
       "  'love',\n",
       "  'main',\n",
       "  'maintain',\n",
       "  'make',\n",
       "  'many',\n",
       "  'matter',\n",
       "  'mbndjjfjfjsssf',\n",
       "  'mean',\n",
       "  'medication',\n",
       "  'meditate',\n",
       "  'meditation',\n",
       "  'mental',\n",
       "  'mentally',\n",
       "  'mention',\n",
       "  'mom',\n",
       "  'money',\n",
       "  'morning',\n",
       "  'mother',\n",
       "  'much',\n",
       "  'n',\n",
       "  'name',\n",
       "  'necessary',\n",
       "  'need',\n",
       "  'nervous',\n",
       "  'network',\n",
       "  'new',\n",
       "  'nice',\n",
       "  'night',\n",
       "  'nights',\n",
       "  'nobody',\n",
       "  'nothing',\n",
       "  'oh',\n",
       "  'ok',\n",
       "  'okay',\n",
       "  'ola',\n",
       "  'one',\n",
       "  'ones',\n",
       "  'open',\n",
       "  'options',\n",
       "  'overcome',\n",
       "  'pass',\n",
       "  'past',\n",
       "  'people',\n",
       "  'person',\n",
       "  'plan',\n",
       "  'please',\n",
       "  'possible',\n",
       "  'possibly',\n",
       "  'practice',\n",
       "  'prepare',\n",
       "  'present',\n",
       "  'prevent',\n",
       "  'probably',\n",
       "  'problems',\n",
       "  'professional',\n",
       "  'professionals',\n",
       "  'proper',\n",
       "  'purpose',\n",
       "  'question',\n",
       "  'rain',\n",
       "  'really',\n",
       "  'reason',\n",
       "  'receive',\n",
       "  'recover',\n",
       "  'relationship',\n",
       "  'reliable',\n",
       "  'repeat',\n",
       "  'reply',\n",
       "  'require',\n",
       "  'response',\n",
       "  'revoir',\n",
       "  'right',\n",
       "  'robot',\n",
       "  'root',\n",
       "  'sad',\n",
       "  'sadness',\n",
       "  'say',\n",
       "  'sayonara',\n",
       "  'scar',\n",
       "  'see',\n",
       "  'seem',\n",
       "  'sense',\n",
       "  'shut',\n",
       "  'sick',\n",
       "  'sight',\n",
       "  'sign',\n",
       "  'significance',\n",
       "  'significant',\n",
       "  'sister',\n",
       "  'sleep',\n",
       "  'smart',\n",
       "  'social',\n",
       "  'someone',\n",
       "  'something',\n",
       "  'sound',\n",
       "  'spell',\n",
       "  'start',\n",
       "  'stay',\n",
       "  'stick',\n",
       "  'still',\n",
       "  'stop',\n",
       "  'story',\n",
       "  'stress',\n",
       "  'stupid',\n",
       "  'suffer',\n",
       "  'suicide',\n",
       "  'support',\n",
       "  'suppose',\n",
       "  'sure',\n",
       "  'symptoms',\n",
       "  'tag',\n",
       "  'take',\n",
       "  'tale',\n",
       "  'talk',\n",
       "  'tell',\n",
       "  'telltale',\n",
       "  'terrible',\n",
       "  'thank',\n",
       "  'thats',\n",
       "  'thee',\n",
       "  'therapist',\n",
       "  'therapists',\n",
       "  'therapy',\n",
       "  'theres',\n",
       "  'thing',\n",
       "  'things',\n",
       "  'think',\n",
       "  'time',\n",
       "  'today',\n",
       "  'tolerate',\n",
       "  'top',\n",
       "  'touch',\n",
       "  'travel',\n",
       "  'treatment',\n",
       "  'treatments',\n",
       "  'trust',\n",
       "  'trustworthy',\n",
       "  'type',\n",
       "  'unable',\n",
       "  'understand',\n",
       "  'unwell',\n",
       "  'useful',\n",
       "  'useless',\n",
       "  'vvvvvvvvvvvvv',\n",
       "  'wake',\n",
       "  'want',\n",
       "  'warm',\n",
       "  'warn',\n",
       "  'wasnt',\n",
       "  'way',\n",
       "  'well',\n",
       "  'whatever',\n",
       "  'whats',\n",
       "  'wonder',\n",
       "  'wonderful',\n",
       "  'workers',\n",
       "  'worry',\n",
       "  'worthless',\n",
       "  'would',\n",
       "  'wrong',\n",
       "  'xcaxxczcq',\n",
       "  'yeah',\n",
       "  'yes',\n",
       "  'youre'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocab for patterns column\n",
    "\n",
    "vocab = sorted(list(set(' '.join(texts['patterns'].unique()).split(' '))))\n",
    "len(vocab), vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73694a",
   "metadata": {},
   "source": [
    "#### So, every sentence in our dataset will be of size (1 x 330) and our BOW vectorization will be of size (80 x 1 x 330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62f09bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1, 330)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = np.zeros((len(texts), 1, len(vocab)))\n",
    "dataset_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c82cd35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hola': 1, 'tag': 1, 'hi': 2, 'ola': 1, 'howdy': 1, 'hello': 1, 'anyone': 1, 'guten': 1, 'konnichiwa': 1, 'bonjour': 1, 'hey': 2}\n",
      "{'great': 3, 'morning': 1, 'nice': 3, 'good': 5, 'start': 9, 'day': 8, 'wake': 2, 'warm': 1}\n",
      "{'morning': 3, 'nice': 4, 'good': 8, 'day': 7, 'start': 3, 'afternoon': 1}\n",
      "{'morning': 3, 'great': 1, 'nice': 3, 'good': 8, 'day': 4, 'start': 2, 'even': 1, 'night': 4}\n",
      "{'great': 3, 'nice': 4, 'good': 4, 'day': 2, 'wonderful': 1, 'even': 4, 'night': 5}\n",
      "{'alright': 1, 'later': 1, 'goodbye': 3, 'bye': 4, 'see': 1, 'well': 1, 'revoir': 1, 'fare': 1, 'au': 1, 'sayonara': 1, 'thee': 1, 'ok': 1}\n",
      "{'help': 2, 'useful': 1, 'thats': 2, 'assistance': 1, 'much': 4, 'helpful': 2, 'thank': 7}\n",
      "{'vvvvvvvvvvvvv': 1, 'person': 1, 'indeed': 1, 'xcaxxczcq': 1, 'mbndjjfjfjsssf': 1, 'n': 1, 'rain': 1, 'theres': 1, 'something': 1, 'someone': 2}\n",
      "{'anything': 1, 'significance': 2, 'lot': 1, 'nothing': 4, 'much': 3, 'wasnt': 1, 'isnt': 1, 'significant': 6}\n",
      "{'whats': 1, 'call': 1, 'name': 3, 'person': 1, 'know': 1, 'let': 1, 'tell': 3}\n",
      "{'able': 1, 'plan': 2, 'go': 1}\n",
      "{'create': 2, 'arrive': 1, 'make': 5, 'get': 2, 'creator': 1}\n",
      "{'call': 2, 'name': 7, 'travel': 1, 'pass': 1, 'correctly': 1, 'im': 3, 'go': 2, 'spell': 1}\n",
      "{'support': 2, 'help': 6, 'could': 1, 'give': 1, 'please': 2, 'need': 4, 'assistance': 1, 'hand': 1}\n",
      "{'feel': 8, 'well': 1, 'good': 1, 'empty': 1, 'anyone': 1, 'dont': 3, 'bad': 1, 'lonely': 3, 'sad': 3, 'im': 1}\n",
      "{'burn': 1, 'feel': 3, 'stress': 8, 'still': 2, 'im': 1, 'stick': 3}\n",
      "{'like': 2, 'anything': 3, 'feel': 2, 'worthless': 2, 'cannot': 1, 'cant': 1, 'make': 3, 'nothing': 2, 'useless': 1, 'anymore': 2, 'enjoy': 1, 'one': 2, 'unable': 1, 'sense': 3, 'nobody': 1}\n",
      "{'believe': 1, 'longer': 1, 'suffer': 1, 'cant': 2, 'take': 2, 'depress': 7, 'tolerate': 1, 'anymore': 2, 'depression': 2, 'think': 2, 'im': 3}\n",
      "{'great': 3, 'feel': 5, 'cheerful': 1, 'well': 1, 'today': 2, 'good': 2, 'happy': 3, 'fine': 1, 'ok': 1, 'im': 4}\n",
      "{'okay': 1, 'person': 1, 'oh': 1, 'whatever': 1, 'really': 1, 'see': 1, 'yeah': 1, 'nice': 1, 'k': 2, 'yes': 1, 'fine': 1, 'ok': 1}\n",
      "{'anxious': 5, 'feel': 4, 'worry': 1, 'nervous': 6, 'im': 5}\n",
      "{'discuss': 1, 'cant': 2, 'bring': 1, 'stop': 1, 'dont': 5, 'want': 3, 'talk': 2, 'shut': 2, 'away': 4, 'stay': 4, 'open': 2}\n",
      "{'past': 1, 'sleep': 10, 'last': 1, 'insomnia': 1, 'suffer': 1, 'well': 1, 'cant': 2, 'seem': 1, 'long': 1, 'good': 2, 'havent': 8, 'insominia': 1, 'go': 1, 'days': 4, 'nights': 2, 'time': 1, 'proper': 1}\n",
      "{'terrible': 1, 'feel': 3, 'awful': 1, 'scar': 4, 'way': 3, 'dont': 3, 'want': 3, 'afraid': 1, 'sound': 2, 'im': 3}\n",
      "{'dad': 2, 'friend': 1, 'mother': 1, 'father': 1, 'family': 1, 'sister': 3, 'pass': 6, 'mom': 2, 'brother': 1, 'away': 6, 'die': 6, 'someone': 1}\n",
      "{'help': 3, 'know': 5, 'cant': 4, 'cannot': 1, 'understand': 3, 'useless': 1, 'dont': 2, 'possibly': 1, 'youre': 3, 'go': 4, 'unable': 1, 'robot': 2, 'would': 2, 'nobody': 1, 'im': 4}\n",
      "{'else': 4, 'anything': 1, 'thats': 3, 'say': 3, 'yes': 1, 'nothing': 4, 'dont': 1, 'sight': 1, 'would': 3}\n",
      "{'think': 2, 'like': 2, 'contemplate': 1, 'love': 1, 'kill': 7, 'commit': 2, 'want': 2, 'consider': 1, 'ive': 3, 'go': 2, 'would': 3, 'suicide': 2, 'die': 3}\n",
      "{'like': 5, 'believe': 2, 'reliable': 1, 'right': 1, 'much': 2, 'dont': 8, 'trustworthy': 1, 'trust': 1, 'think': 3, 'hate': 1}\n",
      "{'like': 4, 'dislike': 2, 'know': 4, 'dont': 3, 'hate': 2}\n",
      "{'financial': 2, 'problems': 1, 'family': 1, 'girlfriend': 1, 'exams': 2, 'friends': 1, 'relationship': 3, 'issue': 1, 'boyfriend': 1, 'money': 1}\n",
      "{'story': 1, 'need': 1, 'know': 1, 'new': 3, 'let': 1, 'another': 1, 'anecdote': 1, 'tell': 10, 'better': 1, 'funnier': 1, 'joke': 8, 'something': 1, 'funny': 5, 'tale': 1}\n",
      "{'mention': 6, 'keep': 1, 'repeat': 3, 'already': 7, 'say': 1, 'tell': 2}\n",
      "{'discuss': 1, 'answer': 2, 'make': 4, 'response': 1, 'say': 1, 'talk': 1, 'sense': 4, 'mean': 1, 'doesnt': 2, 'wrong': 4, 'reply': 1}\n",
      "{'stupid': 3, 'dumb': 3, 'smart': 2, 'youre': 3, 'insane': 2, 'think': 1, 'crazy': 2}\n",
      "{'whats': 1, 'anything': 1, 'locate': 1, 'live': 2, 'present': 1, 'location': 3}\n",
      "{'else': 5, 'like': 1, 'discuss': 5, 'let': 2, 'dont': 4, 'want': 6, 'something': 5, 'talk': 7, 'would': 1}\n",
      "{'friends': 7, 'dont': 3, 'many': 2}\n",
      "{'else': 2, 'question': 2, 'anything': 4, 'possible': 7, 'ask': 10, 'something': 6, 'inquire': 1}\n",
      "{'prepare': 9, 'feel': 9, 'well': 8, 'stress': 9, 'due': 1, 'approach': 1, 'dont': 9, 'exams': 9, 'ive': 3, 'enough': 5, 'think': 9, 'im': 2, 'probably': 4}\n",
      "{'really': 4, 'cant': 1, 'suppose': 1, 'guess': 2, 'exams': 4, 'dont': 1, 'isnt': 1, 'think': 6}\n",
      "{'like': 7, 'know': 5, 'yes': 1, 'sure': 1, 'want': 4, 'would': 6, 'ok': 1, 'id': 1, 'learn': 6}\n",
      "{'need': 2, 'break': 6, 'yeah': 2, 'right': 2, 'take': 1, 'correct': 6, 'youre': 6, 'get': 1, 'absolutely': 3, 'deserve': 3}\n",
      "{'could': 6, 'like': 7, 'useful': 11, 'seem': 1, 'would': 1, 'helpful': 1, 'sound': 11, 'hmmm': 1}\n",
      "{'feel': 11, 'better': 11, 'say': 5, 'lot': 2, 'much': 3, 'thank': 4, 'tell': 2, 'alot': 1, 'im': 1}\n",
      "{'keep': 4, 'continue': 4, 'meditate': 1, 'practice': 10, 'ill': 2, 'focus': 12, 'much': 1, 'meditation': 10, 'control': 12, 'thank': 1}\n",
      "{'help': 4, 'appreciate': 1, 'like': 1, 'need': 9, 'assistance': 3, 'want': 1, 'something': 3, 'would': 2, 'advice': 5, 'someone': 1}\n",
      "{'like': 2, 'need': 3, 'know': 5, 'health': 12, 'want': 3, 'dont': 2, 'much': 1, 'aware': 3, 'enough': 1, 'mental': 12, 'im': 1, 'would': 2, 'issue': 2, 'learn': 4, 'interest': 1}\n",
      "{'else': 1, 'like': 1, 'thing': 1, 'fact': 2, 'know': 5, 'need': 1, 'let': 2, 'health': 12, 'another': 1, 'want': 1, 'something': 2, 'mental': 12, 'would': 1, 'tell': 7}\n",
      "{'define': 4, 'health': 12, 'understand': 1, 'purpose': 1, 'something': 2, 'mental': 12, 'mean': 3}\n",
      "{'crucial': 1, 'significance': 1, 'health': 11, 'matter': 3, 'important': 5, 'mental': 11, 'importance': 1, 'mean': 1}\n",
      "{'define': 1, 'depression': 4}\n",
      "{'know': 2, 'suffer': 2, 'possible': 1, 'depress': 4, 'ill': 4, 'dont': 1, 'wonder': 2, 'depression': 4, 'mentally': 4}\n",
      "{'suppose': 2, 'therapists': 2, 'therapist': 9}\n",
      "{'therapy': 12, 'need': 3, 'require': 1, 'wonder': 2, 'receive': 1, 'necessary': 2}\n",
      "{'illnesses': 1, 'illness': 10, 'talk': 1, 'mental': 12, 'mean': 9, 'disorder': 1}\n",
      "{'affect': 6, 'people': 5, 'suffer': 1, 'illness': 12, 'cause': 4, 'mental': 12}\n",
      "{'common': 4, 'main': 2, 'illnesses': 2, 'illness': 10, 'cause': 10, 'mental': 12, 'root': 1, 'top': 2}\n",
      "{'telltale': 1, 'sign': 10, 'warn': 5, 'illness': 12, 'symptoms': 2, 'mental': 12}\n",
      "{'people': 6, 'possible': 9, 'illnesses': 5, 'illness': 7, 'chance': 1, 'recover': 8, 'mental': 12, 'get': 3, 'overcome': 1}\n",
      "{'person': 3, 'know': 8, 'disorder': 8, 'symptoms': 1, 'mental': 8, 'appear': 1, 'someone': 5}\n",
      "{'need': 2, 'health': 12, 'child': 7, 'professional': 12, 'look': 1, 'find': 7, 'get': 1, 'mental': 12, 'im': 2}\n",
      "{'choices': 1, 'ones': 1, 'currently': 1, 'treatment': 5, 'treatments': 3, 'available': 9, 'options': 7}\n",
      "{'become': 3, 'need': 8, 'know': 9, 'treatment': 12, 'dont': 1, 'im': 1, 'sure': 2, 'get': 5, 'involve': 12}\n",
      "{'professionals': 8, 'different': 3, 'health': 12, 'differences': 5, 'mental': 12, 'difference': 3, 'workers': 4}\n",
      "{'health': 12, 'right': 1, 'child': 12, 'professional': 12, 'find': 6, 'get': 2, 'mental': 12}\n",
      "{'help': 3, 'else': 2, 'assistance': 2, 'find': 1, 'get': 4}\n",
      "{'know': 8, 'new': 12, 'take': 1, 'start': 8, 'medication': 11, 'drug': 1, 'aware': 4}\n",
      "{'help': 2, 'therapy': 5, 'therapist': 4, 'assistance': 1, 'want': 2, 'find': 5, 'go': 3, 'get': 5}\n",
      "{'like': 2, 'information': 6, 'know': 2, 'treatment': 12, 'health': 12, 'want': 2, 'type': 1, 'look': 4, 'find': 2, 'mental': 12, 'would': 2, 'im': 2, 'learn': 4}\n",
      "{'professionals': 9, 'health': 12, 'exist': 2, 'kinds': 2, 'kind': 1, 'type': 8, 'mental': 12, 'different': 9, 'available': 1, 'workers': 3}\n",
      "{'support': 11, 'like': 2, 'need': 1, 'want': 2, 'group': 11, 'find': 7, 'look': 3, 'talk': 1, 'go': 1, 'would': 1, 'id': 1, 'im': 2, 'someone': 1}\n",
      "{'do': 2, 'problems': 6, 'possible': 4, 'health': 12, 'stop': 6, 'prevent': 6, 'mental': 12, 'issue': 6}\n",
      "{'cure': 12, 'problems': 4, 'possible': 1, 'health': 11, 'illness': 1, 'mental': 12, 'issue': 5}\n",
      "{'problems': 7, 'main': 2, 'health': 12, 'reason': 1, 'cause': 11, 'something': 3, 'mental': 12, 'issue': 5, 'top': 1}\n",
      "{'concern': 3, 'health': 12, 'worry': 8, 'mental': 12, 'im': 7}\n",
      "{'know': 9, 'well': 7, 'feel': 3, 'possible': 4, 'unwell': 3, 'sure': 1, 'dont': 1, 'sick': 2, 'tell': 2, 'im': 12}\n",
      "{'do': 1, 'connections': 3, 'people': 2, 'maintain': 4, 'keep': 4, 'like': 1, 'network': 1, 'feel': 1, 'possible': 2, 'social': 4, 'lonely': 1, 'friends': 6, 'touch': 8, 'would': 1, 'stay': 4}\n",
      "{'whats': 2, 'different': 2, 'anxiety': 12, 'stress': 12, 'differences': 2, 'difference': 6}\n",
      "{'whats': 1, 'sadness': 12, 'differences': 2, 'depression': 12, 'different': 3, 'difference': 6, 'things': 1}\n"
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "for i in texts['patterns'].unique():\n",
    "    word_dict = {}\n",
    "    for c, word in enumerate(list(set(i.split(\" \")))):\n",
    "        word_dict[word] = i.split(\" \").count(word)\n",
    "    print(word_dict)\n",
    "    for k, v in word_dict.items():\n",
    "        vocab_index = vocab.index(k)\n",
    "        word_count = v\n",
    "        dataset_size[ind][0][vocab_index] = word_count\n",
    "\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "591b0db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 2., 2., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14225501",
   "metadata": {},
   "source": [
    "So, we are now done with Bag Of Words. Vectors are now ready to pass to models.\n",
    "\n",
    "**Disadvantages of BOW:**\n",
    "\n",
    "- Bad representation, no context and position accounted for in the vectorization\n",
    "- Sparse vector\n",
    "- Fails for a new word\n",
    "\n",
    "**Advantages of BOW:**\n",
    "\n",
    "- Less sparse than OHE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd4240",
   "metadata": {},
   "source": [
    "## TF-IDF (Term frequency - Inverse Document Frequency)\n",
    "\n",
    "TF-IDF is a better technique for word representation than BOW and OHE. It is not sparse, and do captures word relations in a document to some extent. There are 2 terms in TF-IDF, lets understand both:\n",
    "\n",
    "- **TF (Term Frequncy):** As the name suggest, it is the frequncy of a word in the sentence. \n",
    "\n",
    "TF = #times word appears in the sentence / Total number of words in the sentence\n",
    "\n",
    "- **IDF (Inverse Document Frequency):** Simply put, it is the inverse of document frequency. But what is document frequncy? Document frequency is the ratio of number of documents where that word appears and the total number of documents.\n",
    "\n",
    "So, IDF = Inverse(Document Frequncy)\n",
    "\n",
    "and, Document Frequency = #document where word w appears / total number of documents\n",
    "\n",
    "So, IDF = log(total number of documents / #document where word w appears)\n",
    "\n",
    "Log is applied so that IDF doesn't shoot up in case of low numerator.\n",
    "\n",
    "Now **TF-IDF = TF x IDF**\n",
    "\n",
    "\n",
    "Let's build TF-IDF on the pattern column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0c6b0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'able': 0,\n",
       " 'absolutely': 0,\n",
       " 'advice': 0,\n",
       " 'affect': 0,\n",
       " 'afraid': 0,\n",
       " 'afternoon': 0,\n",
       " 'alot': 0,\n",
       " 'already': 0,\n",
       " 'alright': 0,\n",
       " 'anecdote': 0,\n",
       " 'another': 0,\n",
       " 'answer': 0,\n",
       " 'anxiety': 0,\n",
       " 'anxious': 0,\n",
       " 'anymore': 0,\n",
       " 'anyone': 0,\n",
       " 'anything': 0,\n",
       " 'appear': 0,\n",
       " 'appreciate': 0,\n",
       " 'approach': 0,\n",
       " 'arrive': 0,\n",
       " 'ask': 0,\n",
       " 'assistance': 0,\n",
       " 'au': 0,\n",
       " 'available': 0,\n",
       " 'aware': 0,\n",
       " 'away': 0,\n",
       " 'awful': 0,\n",
       " 'bad': 0,\n",
       " 'become': 0,\n",
       " 'believe': 0,\n",
       " 'better': 0,\n",
       " 'bonjour': 0,\n",
       " 'boyfriend': 0,\n",
       " 'break': 0,\n",
       " 'bring': 0,\n",
       " 'brother': 0,\n",
       " 'burn': 0,\n",
       " 'bye': 0,\n",
       " 'call': 0,\n",
       " 'cannot': 0,\n",
       " 'cant': 0,\n",
       " 'cause': 0,\n",
       " 'chance': 0,\n",
       " 'cheerful': 0,\n",
       " 'child': 0,\n",
       " 'choices': 0,\n",
       " 'commit': 0,\n",
       " 'common': 0,\n",
       " 'concern': 0,\n",
       " 'connections': 0,\n",
       " 'consider': 0,\n",
       " 'contemplate': 0,\n",
       " 'continue': 0,\n",
       " 'control': 0,\n",
       " 'correct': 0,\n",
       " 'correctly': 0,\n",
       " 'could': 0,\n",
       " 'crazy': 0,\n",
       " 'create': 0,\n",
       " 'creator': 0,\n",
       " 'crucial': 0,\n",
       " 'cure': 0,\n",
       " 'currently': 0,\n",
       " 'dad': 0,\n",
       " 'day': 0,\n",
       " 'days': 0,\n",
       " 'define': 0,\n",
       " 'depress': 0,\n",
       " 'depression': 0,\n",
       " 'deserve': 0,\n",
       " 'die': 0,\n",
       " 'difference': 0,\n",
       " 'differences': 0,\n",
       " 'different': 0,\n",
       " 'discuss': 0,\n",
       " 'dislike': 0,\n",
       " 'disorder': 0,\n",
       " 'do': 0,\n",
       " 'doesnt': 0,\n",
       " 'dont': 0,\n",
       " 'drug': 0,\n",
       " 'due': 0,\n",
       " 'dumb': 0,\n",
       " 'else': 0,\n",
       " 'empty': 0,\n",
       " 'enjoy': 0,\n",
       " 'enough': 0,\n",
       " 'even': 0,\n",
       " 'exams': 0,\n",
       " 'exist': 0,\n",
       " 'fact': 0,\n",
       " 'family': 0,\n",
       " 'fare': 0,\n",
       " 'father': 0,\n",
       " 'feel': 0,\n",
       " 'financial': 0,\n",
       " 'find': 0,\n",
       " 'fine': 0,\n",
       " 'focus': 0,\n",
       " 'friend': 0,\n",
       " 'friends': 0,\n",
       " 'funnier': 0,\n",
       " 'funny': 0,\n",
       " 'get': 0,\n",
       " 'girlfriend': 0,\n",
       " 'give': 0,\n",
       " 'go': 0,\n",
       " 'good': 0,\n",
       " 'goodbye': 0,\n",
       " 'great': 0,\n",
       " 'group': 0,\n",
       " 'guess': 0,\n",
       " 'guten': 0,\n",
       " 'hand': 0,\n",
       " 'happy': 0,\n",
       " 'hate': 0,\n",
       " 'havent': 0,\n",
       " 'health': 0,\n",
       " 'hello': 0,\n",
       " 'help': 0,\n",
       " 'helpful': 0,\n",
       " 'hey': 0,\n",
       " 'hi': 0,\n",
       " 'hmmm': 0,\n",
       " 'hola': 0,\n",
       " 'howdy': 0,\n",
       " 'id': 0,\n",
       " 'ill': 0,\n",
       " 'illness': 0,\n",
       " 'illnesses': 0,\n",
       " 'im': 0,\n",
       " 'importance': 0,\n",
       " 'important': 0,\n",
       " 'indeed': 0,\n",
       " 'information': 0,\n",
       " 'inquire': 0,\n",
       " 'insane': 0,\n",
       " 'insominia': 0,\n",
       " 'insomnia': 0,\n",
       " 'interest': 0,\n",
       " 'involve': 0,\n",
       " 'isnt': 0,\n",
       " 'issue': 0,\n",
       " 'ive': 0,\n",
       " 'joke': 0,\n",
       " 'k': 0,\n",
       " 'keep': 0,\n",
       " 'kill': 0,\n",
       " 'kind': 0,\n",
       " 'kinds': 0,\n",
       " 'know': 0,\n",
       " 'konnichiwa': 0,\n",
       " 'last': 0,\n",
       " 'later': 0,\n",
       " 'learn': 0,\n",
       " 'let': 0,\n",
       " 'like': 0,\n",
       " 'live': 0,\n",
       " 'locate': 0,\n",
       " 'location': 0,\n",
       " 'lonely': 0,\n",
       " 'long': 0,\n",
       " 'longer': 0,\n",
       " 'look': 0,\n",
       " 'lot': 0,\n",
       " 'love': 0,\n",
       " 'main': 0,\n",
       " 'maintain': 0,\n",
       " 'make': 0,\n",
       " 'many': 0,\n",
       " 'matter': 0,\n",
       " 'mbndjjfjfjsssf': 0,\n",
       " 'mean': 0,\n",
       " 'medication': 0,\n",
       " 'meditate': 0,\n",
       " 'meditation': 0,\n",
       " 'mental': 0,\n",
       " 'mentally': 0,\n",
       " 'mention': 0,\n",
       " 'mom': 0,\n",
       " 'money': 0,\n",
       " 'morning': 0,\n",
       " 'mother': 0,\n",
       " 'much': 0,\n",
       " 'n': 0,\n",
       " 'name': 0,\n",
       " 'necessary': 0,\n",
       " 'need': 0,\n",
       " 'nervous': 0,\n",
       " 'network': 0,\n",
       " 'new': 0,\n",
       " 'nice': 0,\n",
       " 'night': 0,\n",
       " 'nights': 0,\n",
       " 'nobody': 0,\n",
       " 'nothing': 0,\n",
       " 'oh': 0,\n",
       " 'ok': 0,\n",
       " 'okay': 0,\n",
       " 'ola': 0,\n",
       " 'one': 0,\n",
       " 'ones': 0,\n",
       " 'open': 0,\n",
       " 'options': 0,\n",
       " 'overcome': 0,\n",
       " 'pass': 0,\n",
       " 'past': 0,\n",
       " 'people': 0,\n",
       " 'person': 0,\n",
       " 'plan': 0,\n",
       " 'please': 0,\n",
       " 'possible': 0,\n",
       " 'possibly': 0,\n",
       " 'practice': 0,\n",
       " 'prepare': 0,\n",
       " 'present': 0,\n",
       " 'prevent': 0,\n",
       " 'probably': 0,\n",
       " 'problems': 0,\n",
       " 'professional': 0,\n",
       " 'professionals': 0,\n",
       " 'proper': 0,\n",
       " 'purpose': 0,\n",
       " 'question': 0,\n",
       " 'rain': 0,\n",
       " 'really': 0,\n",
       " 'reason': 0,\n",
       " 'receive': 0,\n",
       " 'recover': 0,\n",
       " 'relationship': 0,\n",
       " 'reliable': 0,\n",
       " 'repeat': 0,\n",
       " 'reply': 0,\n",
       " 'require': 0,\n",
       " 'response': 0,\n",
       " 'revoir': 0,\n",
       " 'right': 0,\n",
       " 'robot': 0,\n",
       " 'root': 0,\n",
       " 'sad': 0,\n",
       " 'sadness': 0,\n",
       " 'say': 0,\n",
       " 'sayonara': 0,\n",
       " 'scar': 0,\n",
       " 'see': 0,\n",
       " 'seem': 0,\n",
       " 'sense': 0,\n",
       " 'shut': 0,\n",
       " 'sick': 0,\n",
       " 'sight': 0,\n",
       " 'sign': 0,\n",
       " 'significance': 0,\n",
       " 'significant': 0,\n",
       " 'sister': 0,\n",
       " 'sleep': 0,\n",
       " 'smart': 0,\n",
       " 'social': 0,\n",
       " 'someone': 0,\n",
       " 'something': 0,\n",
       " 'sound': 0,\n",
       " 'spell': 0,\n",
       " 'start': 0,\n",
       " 'stay': 0,\n",
       " 'stick': 0,\n",
       " 'still': 0,\n",
       " 'stop': 0,\n",
       " 'story': 0,\n",
       " 'stress': 0,\n",
       " 'stupid': 0,\n",
       " 'suffer': 0,\n",
       " 'suicide': 0,\n",
       " 'support': 0,\n",
       " 'suppose': 0,\n",
       " 'sure': 0,\n",
       " 'symptoms': 0,\n",
       " 'tag': 0,\n",
       " 'take': 0,\n",
       " 'tale': 0,\n",
       " 'talk': 0,\n",
       " 'tell': 0,\n",
       " 'telltale': 0,\n",
       " 'terrible': 0,\n",
       " 'thank': 0,\n",
       " 'thats': 0,\n",
       " 'thee': 0,\n",
       " 'therapist': 0,\n",
       " 'therapists': 0,\n",
       " 'therapy': 0,\n",
       " 'theres': 0,\n",
       " 'thing': 0,\n",
       " 'things': 0,\n",
       " 'think': 0,\n",
       " 'time': 0,\n",
       " 'today': 0,\n",
       " 'tolerate': 0,\n",
       " 'top': 0,\n",
       " 'touch': 0,\n",
       " 'travel': 0,\n",
       " 'treatment': 0,\n",
       " 'treatments': 0,\n",
       " 'trust': 0,\n",
       " 'trustworthy': 0,\n",
       " 'type': 0,\n",
       " 'unable': 0,\n",
       " 'understand': 0,\n",
       " 'unwell': 0,\n",
       " 'useful': 0,\n",
       " 'useless': 0,\n",
       " 'vvvvvvvvvvvvv': 0,\n",
       " 'wake': 0,\n",
       " 'want': 0,\n",
       " 'warm': 0,\n",
       " 'warn': 0,\n",
       " 'wasnt': 0,\n",
       " 'way': 0,\n",
       " 'well': 0,\n",
       " 'whatever': 0,\n",
       " 'whats': 0,\n",
       " 'wonder': 0,\n",
       " 'wonderful': 0,\n",
       " 'workers': 0,\n",
       " 'worry': 0,\n",
       " 'worthless': 0,\n",
       " 'would': 0,\n",
       " 'wrong': 0,\n",
       " 'xcaxxczcq': 0,\n",
       " 'yeah': 0,\n",
       " 'yes': 0,\n",
       " 'youre': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs = {v: 0 for v in vocab}\n",
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7b1d651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anyone',\n",
       " 'ola',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'howdy',\n",
       " 'konnichiwa',\n",
       " 'guten',\n",
       " 'tag',\n",
       " 'hi',\n",
       " 'hola',\n",
       " 'hey',\n",
       " 'bonjour',\n",
       " 'hello',\n",
       " 'great',\n",
       " 'wake',\n",
       " 'good',\n",
       " 'start',\n",
       " 'day',\n",
       " 'great',\n",
       " 'start',\n",
       " 'day',\n",
       " 'good',\n",
       " 'start',\n",
       " 'day',\n",
       " 'warm',\n",
       " 'start',\n",
       " 'day',\n",
       " 'great',\n",
       " 'start',\n",
       " 'day',\n",
       " 'nice',\n",
       " 'start',\n",
       " 'good',\n",
       " 'start',\n",
       " 'day',\n",
       " 'nice',\n",
       " 'wake',\n",
       " 'nice',\n",
       " 'start',\n",
       " 'day',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'good',\n",
       " 'start',\n",
       " 'day',\n",
       " 'nice',\n",
       " 'day',\n",
       " 'good',\n",
       " 'start',\n",
       " 'day',\n",
       " 'good',\n",
       " 'day',\n",
       " 'good',\n",
       " 'afternoon',\n",
       " 'nice',\n",
       " 'morning',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'nice',\n",
       " 'day',\n",
       " 'good',\n",
       " 'start',\n",
       " 'day',\n",
       " 'nice',\n",
       " 'good',\n",
       " 'start',\n",
       " 'day',\n",
       " 'good',\n",
       " 'day',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'nice',\n",
       " 'day',\n",
       " 'nice',\n",
       " 'morning',\n",
       " 'good',\n",
       " 'night',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'good',\n",
       " 'start',\n",
       " 'day',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'good',\n",
       " 'even',\n",
       " 'good',\n",
       " 'start',\n",
       " 'day',\n",
       " 'great',\n",
       " 'night',\n",
       " 'good',\n",
       " 'day',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'good',\n",
       " 'night',\n",
       " 'good',\n",
       " 'even',\n",
       " 'good',\n",
       " 'night',\n",
       " 'nice',\n",
       " 'nice',\n",
       " 'day',\n",
       " 'good',\n",
       " 'night',\n",
       " 'wonderful',\n",
       " 'night',\n",
       " 'great',\n",
       " 'even',\n",
       " 'good',\n",
       " 'even',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nice',\n",
       " 'even',\n",
       " 'great',\n",
       " 'night',\n",
       " 'great',\n",
       " 'day',\n",
       " 'goodbye',\n",
       " 'ok',\n",
       " 'bye',\n",
       " 'fare',\n",
       " 'thee',\n",
       " 'well',\n",
       " 'goodbye',\n",
       " 'alright',\n",
       " 'bye',\n",
       " 'bye',\n",
       " 'see',\n",
       " 'later',\n",
       " 'sayonara',\n",
       " 'goodbye',\n",
       " 'bye',\n",
       " 'au',\n",
       " 'revoir',\n",
       " 'thats',\n",
       " 'helpful',\n",
       " 'thank',\n",
       " 'much',\n",
       " 'thank',\n",
       " 'much',\n",
       " 'thank',\n",
       " 'thank',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'thank',\n",
       " 'help',\n",
       " 'thank',\n",
       " 'assistance',\n",
       " 'thats',\n",
       " 'useful',\n",
       " 'much',\n",
       " 'much',\n",
       " 'thank',\n",
       " 'person',\n",
       " 'someone',\n",
       " 'rain',\n",
       " 'n',\n",
       " 'someone',\n",
       " 'vvvvvvvvvvvvv',\n",
       " 'theres',\n",
       " 'something',\n",
       " 'indeed',\n",
       " 'xcaxxczcq',\n",
       " 'mbndjjfjfjsssf',\n",
       " 'nothing',\n",
       " 'significant',\n",
       " 'nothing',\n",
       " 'much',\n",
       " 'much',\n",
       " 'significant',\n",
       " 'nothing',\n",
       " 'significant',\n",
       " 'isnt',\n",
       " 'significance',\n",
       " 'significance',\n",
       " 'much',\n",
       " 'nothing',\n",
       " 'significant',\n",
       " 'significant',\n",
       " 'wasnt',\n",
       " 'anything',\n",
       " 'significant',\n",
       " 'lot',\n",
       " 'whats',\n",
       " 'name',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'let',\n",
       " 'know',\n",
       " 'tell',\n",
       " 'call',\n",
       " 'name',\n",
       " 'person',\n",
       " 'name',\n",
       " 'plan',\n",
       " 'plan',\n",
       " 'go',\n",
       " 'able',\n",
       " 'get',\n",
       " 'arrive',\n",
       " 'make',\n",
       " 'creator',\n",
       " 'get',\n",
       " 'make',\n",
       " 'make',\n",
       " 'create',\n",
       " 'create',\n",
       " 'make',\n",
       " 'make',\n",
       " 'name',\n",
       " 'spell',\n",
       " 'correctly',\n",
       " 'name',\n",
       " 'im',\n",
       " 'call',\n",
       " 'name',\n",
       " 'im',\n",
       " 'name',\n",
       " 'im',\n",
       " 'call',\n",
       " 'name',\n",
       " 'travel',\n",
       " 'go',\n",
       " 'name',\n",
       " 'go',\n",
       " 'name',\n",
       " 'pass',\n",
       " 'need',\n",
       " 'help',\n",
       " 'need',\n",
       " 'help',\n",
       " 'help',\n",
       " 'support',\n",
       " 'please',\n",
       " 'could',\n",
       " 'help',\n",
       " 'give',\n",
       " 'hand',\n",
       " 'please',\n",
       " 'help',\n",
       " 'need',\n",
       " 'support',\n",
       " 'help',\n",
       " 'need',\n",
       " 'assistance',\n",
       " 'feel',\n",
       " 'sad',\n",
       " 'feel',\n",
       " 'lonely',\n",
       " 'dont',\n",
       " 'feel',\n",
       " 'well',\n",
       " 'feel',\n",
       " 'bad',\n",
       " 'lonely',\n",
       " 'im',\n",
       " 'sad',\n",
       " 'feel',\n",
       " 'lonely',\n",
       " 'feel',\n",
       " 'sad',\n",
       " 'dont',\n",
       " 'anyone',\n",
       " 'dont',\n",
       " 'feel',\n",
       " 'good',\n",
       " 'feel',\n",
       " 'empty',\n",
       " 'stress',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'stress',\n",
       " 'im',\n",
       " 'stick',\n",
       " 'stress',\n",
       " 'feel',\n",
       " 'stick',\n",
       " 'still',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'burn',\n",
       " 'stress',\n",
       " 'stress',\n",
       " 'still',\n",
       " 'stress',\n",
       " 'stick',\n",
       " 'cannot',\n",
       " 'anything',\n",
       " 'cant',\n",
       " 'anything',\n",
       " 'nothing',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'feel',\n",
       " 'worthless',\n",
       " 'unable',\n",
       " 'anything',\n",
       " 'nothing',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'anymore',\n",
       " 'one',\n",
       " 'like',\n",
       " 'feel',\n",
       " 'worthless',\n",
       " 'useless',\n",
       " 'nobody',\n",
       " 'like',\n",
       " 'one',\n",
       " 'enjoy',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'anymore',\n",
       " 'cant',\n",
       " 'take',\n",
       " 'anymore',\n",
       " 'im',\n",
       " 'depress',\n",
       " 'think',\n",
       " 'im',\n",
       " 'depress',\n",
       " 'cant',\n",
       " 'tolerate',\n",
       " 'anymore',\n",
       " 'longer',\n",
       " 'take',\n",
       " 'depress',\n",
       " 'depression',\n",
       " 'depress',\n",
       " 'depress',\n",
       " 'believe',\n",
       " 'im',\n",
       " 'depress',\n",
       " 'suffer',\n",
       " 'depression',\n",
       " 'think',\n",
       " 'depress',\n",
       " 'im',\n",
       " 'good',\n",
       " 'feel',\n",
       " 'great',\n",
       " 'today',\n",
       " 'cheerful',\n",
       " 'feel',\n",
       " 'great',\n",
       " 'im',\n",
       " 'good',\n",
       " 'im',\n",
       " 'well',\n",
       " 'happy',\n",
       " 'feel',\n",
       " 'great',\n",
       " 'today',\n",
       " 'feel',\n",
       " 'happy',\n",
       " 'feel',\n",
       " 'ok',\n",
       " 'im',\n",
       " 'fine',\n",
       " 'happy',\n",
       " 'k',\n",
       " 'person',\n",
       " 'k',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'fine',\n",
       " 'whatever',\n",
       " 'yeah',\n",
       " 'oh',\n",
       " 'see',\n",
       " 'nice',\n",
       " 'really',\n",
       " 'yes',\n",
       " 'nervous',\n",
       " 'nervous',\n",
       " 'feel',\n",
       " 'anxious',\n",
       " 'feel',\n",
       " 'nervous',\n",
       " 'feel',\n",
       " 'anxious',\n",
       " 'feel',\n",
       " 'nervous',\n",
       " 'im',\n",
       " 'nervous',\n",
       " 'im',\n",
       " 'anxious',\n",
       " 'im',\n",
       " 'worry',\n",
       " 'anxious',\n",
       " 'im',\n",
       " 'nervous',\n",
       " 'im',\n",
       " 'anxious',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'talk',\n",
       " 'stop',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'discuss',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'talk',\n",
       " 'cant',\n",
       " 'open',\n",
       " 'cant',\n",
       " 'bring',\n",
       " 'open',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'shut',\n",
       " 'shut',\n",
       " 'dont',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'dont',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'havent',\n",
       " 'sleep',\n",
       " 'havent',\n",
       " 'sleep',\n",
       " 'long',\n",
       " 'time',\n",
       " 'havent',\n",
       " 'sleep',\n",
       " 'last',\n",
       " 'days',\n",
       " 'havent',\n",
       " 'proper',\n",
       " 'sleep',\n",
       " 'past',\n",
       " 'days',\n",
       " 'havent',\n",
       " 'good',\n",
       " 'nights',\n",
       " 'sleep',\n",
       " 'havent',\n",
       " 'good',\n",
       " 'nights',\n",
       " 'sleep',\n",
       " 'cant',\n",
       " 'sleep',\n",
       " 'suffer',\n",
       " 'insomnia',\n",
       " 'havent',\n",
       " 'sleep',\n",
       " 'days',\n",
       " 'insominia',\n",
       " 'havent',\n",
       " 'sleep',\n",
       " 'well',\n",
       " 'days',\n",
       " 'cant',\n",
       " 'seem',\n",
       " 'go',\n",
       " 'sleep',\n",
       " 'scar',\n",
       " 'afraid',\n",
       " 'im',\n",
       " 'scar',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'feel',\n",
       " 'way',\n",
       " 'sound',\n",
       " 'awful',\n",
       " 'sound',\n",
       " 'terrible',\n",
       " 'im',\n",
       " 'scar',\n",
       " 'im',\n",
       " 'scar',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'feel',\n",
       " 'way',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'feel',\n",
       " 'way',\n",
       " 'mom',\n",
       " 'die',\n",
       " 'dad',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'sister',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'father',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'sister',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'friend',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'dad',\n",
       " 'die',\n",
       " 'sister',\n",
       " 'die',\n",
       " 'someone',\n",
       " 'family',\n",
       " 'die',\n",
       " 'brother',\n",
       " 'die',\n",
       " 'mom',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'mother',\n",
       " 'die',\n",
       " 'cant',\n",
       " 'possibly',\n",
       " 'know',\n",
       " 'im',\n",
       " 'go',\n",
       " 'cant',\n",
       " 'help',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'im',\n",
       " 'go',\n",
       " 'cant',\n",
       " 'know',\n",
       " 'im',\n",
       " 'go',\n",
       " 'youre',\n",
       " 'robot',\n",
       " 'would',\n",
       " 'know',\n",
       " 'cant',\n",
       " 'understand',\n",
       " 'im',\n",
       " 'go',\n",
       " 'unable',\n",
       " 'help',\n",
       " 'would',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'robot',\n",
       " 'cannot',\n",
       " 'help',\n",
       " 'nobody',\n",
       " 'understand',\n",
       " 'dont',\n",
       " 'understand',\n",
       " 'youre',\n",
       " 'useless',\n",
       " 'yes',\n",
       " 'would',\n",
       " 'thats',\n",
       " 'nothing',\n",
       " 'else',\n",
       " 'would',\n",
       " 'would',\n",
       " 'nothing',\n",
       " 'else',\n",
       " 'say',\n",
       " 'thats',\n",
       " 'thats',\n",
       " 'say',\n",
       " 'nothing',\n",
       " 'else',\n",
       " 'sight',\n",
       " 'nothing',\n",
       " 'else',\n",
       " 'dont',\n",
       " 'anything',\n",
       " 'say',\n",
       " 'ive',\n",
       " 'consider',\n",
       " 'kill',\n",
       " 'ive',\n",
       " 'contemplate',\n",
       " 'kill',\n",
       " 'would',\n",
       " 'love',\n",
       " 'die',\n",
       " 'ive',\n",
       " 'think',\n",
       " 'kill',\n",
       " 'want',\n",
       " 'kill',\n",
       " 'want',\n",
       " 'die',\n",
       " 'commit',\n",
       " 'suicide',\n",
       " 'think',\n",
       " 'kill',\n",
       " 'would',\n",
       " 'like',\n",
       " 'kill',\n",
       " 'go',\n",
       " 'commit',\n",
       " 'suicide',\n",
       " 'would',\n",
       " 'like',\n",
       " 'die',\n",
       " 'go',\n",
       " 'kill',\n",
       " 'like',\n",
       " 'much',\n",
       " 'like',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'much',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'right',\n",
       " 'dont',\n",
       " 'believe',\n",
       " 'hate',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'reliable',\n",
       " 'dont',\n",
       " 'trust',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'believe',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'trustworthy',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'know',\n",
       " 'hate',\n",
       " 'like',\n",
       " 'dislike',\n",
       " 'know',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'hate',\n",
       " 'know',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'know',\n",
       " 'dislike',\n",
       " 'relationship',\n",
       " 'exams',\n",
       " 'relationship',\n",
       " 'financial',\n",
       " 'problems',\n",
       " 'exams',\n",
       " 'friends',\n",
       " 'money',\n",
       " 'boyfriend',\n",
       " 'family',\n",
       " 'financial',\n",
       " 'issue',\n",
       " 'girlfriend',\n",
       " 'relationship',\n",
       " 'tell',\n",
       " 'joke',\n",
       " 'tell',\n",
       " 'funny',\n",
       " 'joke',\n",
       " 'tell',\n",
       " 'funny',\n",
       " 'tale',\n",
       " 'tell',\n",
       " 'better',\n",
       " 'joke',\n",
       " 'tell',\n",
       " 'another',\n",
       " 'joke',\n",
       " 'tell',\n",
       " 'funnier',\n",
       " 'joke',\n",
       " 'need',\n",
       " 'new',\n",
       " 'joke',\n",
       " 'let',\n",
       " 'know',\n",
       " 'new',\n",
       " 'joke',\n",
       " 'tell',\n",
       " 'funny',\n",
       " 'story',\n",
       " 'tell',\n",
       " 'something',\n",
       " 'funny',\n",
       " 'tell',\n",
       " 'new',\n",
       " 'joke',\n",
       " 'tell',\n",
       " 'funny',\n",
       " 'anecdote',\n",
       " 'keep',\n",
       " 'repeat',\n",
       " 'already',\n",
       " 'tell',\n",
       " 'mention',\n",
       " 'repeat',\n",
       " 'already',\n",
       " 'tell',\n",
       " 'mention',\n",
       " 'already',\n",
       " 'already',\n",
       " 'mention',\n",
       " 'repeat',\n",
       " 'mention',\n",
       " 'mention',\n",
       " 'already',\n",
       " 'already',\n",
       " 'mention',\n",
       " 'already',\n",
       " 'say',\n",
       " 'talk',\n",
       " 'discuss',\n",
       " 'wrong',\n",
       " 'answer',\n",
       " 'doesnt',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'mean',\n",
       " 'doesnt',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'answer',\n",
       " 'wrong',\n",
       " 'wrong',\n",
       " 'response',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'say',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'wrong',\n",
       " 'reply',\n",
       " 'smart',\n",
       " 'stupid',\n",
       " 'think',\n",
       " 'dumb',\n",
       " 'youre',\n",
       " 'crazy',\n",
       " 'youre',\n",
       " 'insane',\n",
       " 'crazy',\n",
       " 'insane',\n",
       " 'dumb',\n",
       " 'youre',\n",
       " 'stupid',\n",
       " 'smart',\n",
       " 'dumb',\n",
       " 'stupid',\n",
       " 'location',\n",
       " 'live',\n",
       " 'whats',\n",
       " 'location',\n",
       " 'location',\n",
       " 'anything',\n",
       " 'live',\n",
       " 'present',\n",
       " 'locate',\n",
       " 'talk',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'discuss',\n",
       " 'want',\n",
       " 'talk',\n",
       " 'something',\n",
       " 'else',\n",
       " 'talk',\n",
       " 'want',\n",
       " 'discuss',\n",
       " 'something',\n",
       " 'else',\n",
       " 'would',\n",
       " 'like',\n",
       " 'talk',\n",
       " 'something',\n",
       " 'else',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'discuss',\n",
       " 'discuss',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'talk',\n",
       " 'let',\n",
       " 'talk',\n",
       " 'something',\n",
       " 'else',\n",
       " 'let',\n",
       " 'discuss',\n",
       " 'something',\n",
       " 'else',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'talk',\n",
       " 'many',\n",
       " 'friends',\n",
       " 'dont',\n",
       " 'friends',\n",
       " 'friends',\n",
       " 'friends',\n",
       " 'dont',\n",
       " 'friends',\n",
       " 'dont',\n",
       " 'many',\n",
       " 'friends',\n",
       " 'friends',\n",
       " 'anything',\n",
       " 'else',\n",
       " 'ask',\n",
       " 'possible',\n",
       " 'ask',\n",
       " 'possible',\n",
       " 'question',\n",
       " 'something',\n",
       " 'anything',\n",
       " 'ask',\n",
       " 'anything',\n",
       " 'ask',\n",
       " 'possible',\n",
       " 'inquire',\n",
       " 'something',\n",
       " 'possible',\n",
       " 'ask',\n",
       " 'something',\n",
       " 'possible',\n",
       " 'ask',\n",
       " 'something',\n",
       " 'anything',\n",
       " 'else',\n",
       " 'ask',\n",
       " 'ask',\n",
       " 'something',\n",
       " 'possible',\n",
       " 'ask',\n",
       " 'something',\n",
       " 'possible',\n",
       " 'ask',\n",
       " 'question',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'prepare',\n",
       " 'well',\n",
       " 'enough',\n",
       " 'exams',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'ive',\n",
       " 'prepare',\n",
       " 'well',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'ive',\n",
       " 'prepare',\n",
       " 'well',\n",
       " 'enough',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'im',\n",
       " 'prepare',\n",
       " 'exams',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'prepare',\n",
       " 'well',\n",
       " 'exams',\n",
       " 'probably',\n",
       " 'well',\n",
       " 'exams',\n",
       " 'probably',\n",
       " 'exams',\n",
       " 'probably',\n",
       " 'exams',\n",
       " 'approach',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'ive',\n",
       " 'prepare',\n",
       " 'well',\n",
       " 'enough',\n",
       " 'probably',\n",
       " 'due',\n",
       " 'exams',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'prepare',\n",
       " 'well',\n",
       " 'enough',\n",
       " 'exams',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'im',\n",
       " 'prepare',\n",
       " 'exams',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'prepare',\n",
       " 'well',\n",
       " 'enough',\n",
       " 'think',\n",
       " 'exams',\n",
       " 'cant',\n",
       " 'think',\n",
       " 'exams',\n",
       " 'think',\n",
       " 'guess',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'isnt',\n",
       " 'really',\n",
       " 'really',\n",
       " 'guess',\n",
       " 'think',\n",
       " 'exams',\n",
       " 'really',\n",
       " 'really',\n",
       " 'think',\n",
       " 'exams',\n",
       " 'suppose',\n",
       " 'ok',\n",
       " 'sure',\n",
       " 'would',\n",
       " 'like',\n",
       " 'learn',\n",
       " 'want',\n",
       " 'know',\n",
       " 'would',\n",
       " 'like',\n",
       " 'know',\n",
       " 'want',\n",
       " 'know',\n",
       " 'want',\n",
       " 'learn',\n",
       " 'yes',\n",
       " 'would',\n",
       " 'like',\n",
       " 'learn',\n",
       " 'want',\n",
       " 'learn',\n",
       " 'would',\n",
       " 'like',\n",
       " 'learn',\n",
       " 'would',\n",
       " 'like',\n",
       " 'learn',\n",
       " 'id',\n",
       " 'like',\n",
       " 'know',\n",
       " 'would',\n",
       " 'like',\n",
       " 'know',\n",
       " 'need',\n",
       " 'take',\n",
       " 'break',\n",
       " 'need',\n",
       " 'break',\n",
       " 'get',\n",
       " 'break',\n",
       " 'absolutely',\n",
       " 'correct',\n",
       " 'yeah',\n",
       " 'youre',\n",
       " 'right',\n",
       " 'deserve',\n",
       " 'break',\n",
       " 'deserve',\n",
       " 'break',\n",
       " 'youre',\n",
       " 'correct',\n",
       " 'youre',\n",
       " 'correct',\n",
       " 'deserve',\n",
       " 'break',\n",
       " 'youre',\n",
       " 'correct',\n",
       " 'yeah',\n",
       " 'youre',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ' '.join(texts['patterns'].unique()).split(\" \")\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2871cfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'able': 1,\n",
       " 'absolutely': 3,\n",
       " 'advice': 5,\n",
       " 'affect': 6,\n",
       " 'afraid': 1,\n",
       " 'afternoon': 1,\n",
       " 'alot': 1,\n",
       " 'already': 7,\n",
       " 'alright': 1,\n",
       " 'anecdote': 1,\n",
       " 'another': 2,\n",
       " 'answer': 2,\n",
       " 'anxiety': 12,\n",
       " 'anxious': 5,\n",
       " 'anymore': 4,\n",
       " 'anyone': 2,\n",
       " 'anything': 10,\n",
       " 'appear': 1,\n",
       " 'appreciate': 1,\n",
       " 'approach': 1,\n",
       " 'arrive': 1,\n",
       " 'ask': 10,\n",
       " 'assistance': 8,\n",
       " 'au': 1,\n",
       " 'available': 10,\n",
       " 'aware': 7,\n",
       " 'away': 10,\n",
       " 'awful': 1,\n",
       " 'bad': 1,\n",
       " 'become': 3,\n",
       " 'believe': 3,\n",
       " 'better': 12,\n",
       " 'bonjour': 1,\n",
       " 'boyfriend': 1,\n",
       " 'break': 6,\n",
       " 'bring': 1,\n",
       " 'brother': 1,\n",
       " 'burn': 1,\n",
       " 'bye': 4,\n",
       " 'call': 3,\n",
       " 'cannot': 2,\n",
       " 'cant': 12,\n",
       " 'cause': 25,\n",
       " 'chance': 1,\n",
       " 'cheerful': 1,\n",
       " 'child': 19,\n",
       " 'choices': 1,\n",
       " 'commit': 2,\n",
       " 'common': 4,\n",
       " 'concern': 3,\n",
       " 'connections': 3,\n",
       " 'consider': 1,\n",
       " 'contemplate': 1,\n",
       " 'continue': 4,\n",
       " 'control': 12,\n",
       " 'correct': 6,\n",
       " 'correctly': 1,\n",
       " 'could': 7,\n",
       " 'crazy': 2,\n",
       " 'create': 2,\n",
       " 'creator': 1,\n",
       " 'crucial': 1,\n",
       " 'cure': 12,\n",
       " 'currently': 1,\n",
       " 'dad': 2,\n",
       " 'day': 21,\n",
       " 'days': 4,\n",
       " 'define': 5,\n",
       " 'depress': 11,\n",
       " 'depression': 22,\n",
       " 'deserve': 3,\n",
       " 'die': 9,\n",
       " 'difference': 15,\n",
       " 'differences': 9,\n",
       " 'different': 17,\n",
       " 'discuss': 7,\n",
       " 'dislike': 2,\n",
       " 'disorder': 9,\n",
       " 'do': 3,\n",
       " 'doesnt': 2,\n",
       " 'dont': 47,\n",
       " 'drug': 1,\n",
       " 'due': 1,\n",
       " 'dumb': 3,\n",
       " 'else': 14,\n",
       " 'empty': 1,\n",
       " 'enjoy': 1,\n",
       " 'enough': 6,\n",
       " 'even': 5,\n",
       " 'exams': 15,\n",
       " 'exist': 2,\n",
       " 'fact': 2,\n",
       " 'family': 2,\n",
       " 'fare': 1,\n",
       " 'father': 1,\n",
       " 'feel': 49,\n",
       " 'financial': 2,\n",
       " 'find': 28,\n",
       " 'fine': 2,\n",
       " 'focus': 12,\n",
       " 'friend': 1,\n",
       " 'friends': 14,\n",
       " 'funnier': 1,\n",
       " 'funny': 5,\n",
       " 'get': 23,\n",
       " 'girlfriend': 1,\n",
       " 'give': 1,\n",
       " 'go': 14,\n",
       " 'good': 30,\n",
       " 'goodbye': 3,\n",
       " 'great': 10,\n",
       " 'group': 11,\n",
       " 'guess': 2,\n",
       " 'guten': 1,\n",
       " 'hand': 1,\n",
       " 'happy': 3,\n",
       " 'hate': 3,\n",
       " 'havent': 8,\n",
       " 'health': 154,\n",
       " 'hello': 1,\n",
       " 'help': 20,\n",
       " 'helpful': 3,\n",
       " 'hey': 2,\n",
       " 'hi': 2,\n",
       " 'hmmm': 1,\n",
       " 'hola': 1,\n",
       " 'howdy': 1,\n",
       " 'id': 2,\n",
       " 'ill': 6,\n",
       " 'illness': 52,\n",
       " 'illnesses': 8,\n",
       " 'im': 54,\n",
       " 'importance': 1,\n",
       " 'important': 5,\n",
       " 'indeed': 1,\n",
       " 'information': 6,\n",
       " 'inquire': 1,\n",
       " 'insane': 2,\n",
       " 'insominia': 1,\n",
       " 'insomnia': 1,\n",
       " 'interest': 1,\n",
       " 'involve': 12,\n",
       " 'isnt': 2,\n",
       " 'issue': 19,\n",
       " 'ive': 6,\n",
       " 'joke': 8,\n",
       " 'k': 2,\n",
       " 'keep': 9,\n",
       " 'kill': 7,\n",
       " 'kind': 1,\n",
       " 'kinds': 2,\n",
       " 'know': 64,\n",
       " 'konnichiwa': 1,\n",
       " 'last': 1,\n",
       " 'later': 1,\n",
       " 'learn': 14,\n",
       " 'let': 6,\n",
       " 'like': 37,\n",
       " 'live': 2,\n",
       " 'locate': 1,\n",
       " 'location': 3,\n",
       " 'lonely': 4,\n",
       " 'long': 1,\n",
       " 'longer': 1,\n",
       " 'look': 8,\n",
       " 'lot': 3,\n",
       " 'love': 1,\n",
       " 'main': 4,\n",
       " 'maintain': 4,\n",
       " 'make': 12,\n",
       " 'many': 2,\n",
       " 'matter': 3,\n",
       " 'mbndjjfjfjsssf': 1,\n",
       " 'mean': 14,\n",
       " 'medication': 11,\n",
       " 'meditate': 1,\n",
       " 'meditation': 10,\n",
       " 'mental': 223,\n",
       " 'mentally': 4,\n",
       " 'mention': 6,\n",
       " 'mom': 2,\n",
       " 'money': 1,\n",
       " 'morning': 7,\n",
       " 'mother': 1,\n",
       " 'much': 14,\n",
       " 'n': 1,\n",
       " 'name': 10,\n",
       " 'necessary': 2,\n",
       " 'need': 34,\n",
       " 'nervous': 6,\n",
       " 'network': 1,\n",
       " 'new': 15,\n",
       " 'nice': 15,\n",
       " 'night': 9,\n",
       " 'nights': 2,\n",
       " 'nobody': 2,\n",
       " 'nothing': 10,\n",
       " 'oh': 1,\n",
       " 'ok': 4,\n",
       " 'okay': 1,\n",
       " 'ola': 1,\n",
       " 'one': 2,\n",
       " 'ones': 1,\n",
       " 'open': 2,\n",
       " 'options': 7,\n",
       " 'overcome': 1,\n",
       " 'pass': 7,\n",
       " 'past': 1,\n",
       " 'people': 13,\n",
       " 'person': 6,\n",
       " 'plan': 2,\n",
       " 'please': 2,\n",
       " 'possible': 28,\n",
       " 'possibly': 1,\n",
       " 'practice': 10,\n",
       " 'prepare': 9,\n",
       " 'present': 1,\n",
       " 'prevent': 6,\n",
       " 'probably': 4,\n",
       " 'problems': 18,\n",
       " 'professional': 24,\n",
       " 'professionals': 17,\n",
       " 'proper': 1,\n",
       " 'purpose': 1,\n",
       " 'question': 2,\n",
       " 'rain': 1,\n",
       " 'really': 5,\n",
       " 'reason': 1,\n",
       " 'receive': 1,\n",
       " 'recover': 8,\n",
       " 'relationship': 3,\n",
       " 'reliable': 1,\n",
       " 'repeat': 3,\n",
       " 'reply': 1,\n",
       " 'require': 1,\n",
       " 'response': 1,\n",
       " 'revoir': 1,\n",
       " 'right': 4,\n",
       " 'robot': 2,\n",
       " 'root': 1,\n",
       " 'sad': 3,\n",
       " 'sadness': 12,\n",
       " 'say': 10,\n",
       " 'sayonara': 1,\n",
       " 'scar': 4,\n",
       " 'see': 2,\n",
       " 'seem': 2,\n",
       " 'sense': 7,\n",
       " 'shut': 2,\n",
       " 'sick': 2,\n",
       " 'sight': 1,\n",
       " 'sign': 10,\n",
       " 'significance': 3,\n",
       " 'significant': 6,\n",
       " 'sister': 3,\n",
       " 'sleep': 10,\n",
       " 'smart': 2,\n",
       " 'social': 4,\n",
       " 'someone': 10,\n",
       " 'something': 23,\n",
       " 'sound': 13,\n",
       " 'spell': 1,\n",
       " 'start': 22,\n",
       " 'stay': 8,\n",
       " 'stick': 3,\n",
       " 'still': 2,\n",
       " 'stop': 7,\n",
       " 'story': 1,\n",
       " 'stress': 29,\n",
       " 'stupid': 3,\n",
       " 'suffer': 5,\n",
       " 'suicide': 2,\n",
       " 'support': 13,\n",
       " 'suppose': 3,\n",
       " 'sure': 4,\n",
       " 'symptoms': 3,\n",
       " 'tag': 1,\n",
       " 'take': 4,\n",
       " 'tale': 1,\n",
       " 'talk': 12,\n",
       " 'tell': 26,\n",
       " 'telltale': 1,\n",
       " 'terrible': 1,\n",
       " 'thank': 12,\n",
       " 'thats': 5,\n",
       " 'thee': 1,\n",
       " 'therapist': 13,\n",
       " 'therapists': 2,\n",
       " 'therapy': 17,\n",
       " 'theres': 1,\n",
       " 'thing': 1,\n",
       " 'things': 1,\n",
       " 'think': 23,\n",
       " 'time': 1,\n",
       " 'today': 2,\n",
       " 'tolerate': 1,\n",
       " 'top': 3,\n",
       " 'touch': 8,\n",
       " 'travel': 1,\n",
       " 'treatment': 29,\n",
       " 'treatments': 3,\n",
       " 'trust': 1,\n",
       " 'trustworthy': 1,\n",
       " 'type': 9,\n",
       " 'unable': 2,\n",
       " 'understand': 4,\n",
       " 'unwell': 3,\n",
       " 'useful': 12,\n",
       " 'useless': 2,\n",
       " 'vvvvvvvvvvvvv': 1,\n",
       " 'wake': 2,\n",
       " 'want': 29,\n",
       " 'warm': 1,\n",
       " 'warn': 5,\n",
       " 'wasnt': 1,\n",
       " 'way': 3,\n",
       " 'well': 19,\n",
       " 'whatever': 1,\n",
       " 'whats': 5,\n",
       " 'wonder': 4,\n",
       " 'wonderful': 1,\n",
       " 'workers': 7,\n",
       " 'worry': 9,\n",
       " 'worthless': 2,\n",
       " 'would': 25,\n",
       " 'wrong': 4,\n",
       " 'xcaxxczcq': 1,\n",
       " 'yeah': 3,\n",
       " 'yes': 3,\n",
       " 'youre': 12}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k, v in vocabs.items():\n",
    "    times = words.count(k)\n",
    "    vocabs[k] = times\n",
    "\n",
    "vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ad1d38",
   "metadata": {},
   "source": [
    "We need to build one for each sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00d387f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'anyone': 0.28,\n",
       "  'ola': 0.34,\n",
       "  'hey': 0.67,\n",
       "  'hi': 0.67,\n",
       "  'howdy': 0.34,\n",
       "  'konnichiwa': 0.34,\n",
       "  'guten': 0.34,\n",
       "  'tag': 0.34,\n",
       "  'hola': 0.34,\n",
       "  'bonjour': 0.34,\n",
       "  'hello': 0.34},\n",
       " {'great': 0.28,\n",
       "  'wake': 0.27,\n",
       "  'good': 0.38,\n",
       "  'start': 0.84,\n",
       "  'day': 0.75,\n",
       "  'warm': 0.14,\n",
       "  'nice': 0.26,\n",
       "  'morning': 0.1},\n",
       " {'nice': 0.43,\n",
       "  'day': 0.81,\n",
       "  'good': 0.75,\n",
       "  'start': 0.35,\n",
       "  'afternoon': 0.17,\n",
       "  'morning': 0.38},\n",
       " {'nice': 0.32,\n",
       "  'day': 0.46,\n",
       "  'morning': 0.38,\n",
       "  'good': 0.75,\n",
       "  'night': 0.57,\n",
       "  'start': 0.23,\n",
       "  'even': 0.14,\n",
       "  'great': 0.12},\n",
       " {'good': 0.42,\n",
       "  'even': 0.64,\n",
       "  'night': 0.8,\n",
       "  'nice': 0.48,\n",
       "  'day': 0.26,\n",
       "  'wonderful': 0.19,\n",
       "  'great': 0.39},\n",
       " {'goodbye': 0.77,\n",
       "  'ok': 0.18,\n",
       "  'bye': 1.03,\n",
       "  'fare': 0.26,\n",
       "  'thee': 0.26,\n",
       "  'well': 0.15,\n",
       "  'alright': 0.26,\n",
       "  'see': 0.22,\n",
       "  'later': 0.26,\n",
       "  'sayonara': 0.26,\n",
       "  'au': 0.26,\n",
       "  'revoir': 0.26},\n",
       " {'thats': 0.39,\n",
       "  'helpful': 0.39,\n",
       "  'thank': 1.21,\n",
       "  'much': 0.55,\n",
       "  'help': 0.27,\n",
       "  'assistance': 0.15,\n",
       "  'useful': 0.19},\n",
       " {'person': 0.27,\n",
       "  'someone': 0.5,\n",
       "  'rain': 0.4,\n",
       "  'n': 0.4,\n",
       "  'vvvvvvvvvvvvv': 0.4,\n",
       "  'theres': 0.4,\n",
       "  'something': 0.21,\n",
       "  'indeed': 0.4,\n",
       "  'xcaxxczcq': 0.4,\n",
       "  'mbndjjfjfjsssf': 0.4},\n",
       " {'nothing': 0.69,\n",
       "  'significant': 1.38,\n",
       "  'much': 0.41,\n",
       "  'isnt': 0.19,\n",
       "  'significance': 0.39,\n",
       "  'wasnt': 0.23,\n",
       "  'anything': 0.15,\n",
       "  'lot': 0.19},\n",
       " {'whats': 0.27,\n",
       "  'name': 1.01,\n",
       "  'tell': 0.71,\n",
       "  'let': 0.27,\n",
       "  'know': 0.17,\n",
       "  'call': 0.34,\n",
       "  'person': 0.27},\n",
       " {'plan': 2.19, 'go': 0.61, 'able': 1.1},\n",
       " {'get': 0.42, 'arrive': 0.4, 'make': 1.49, 'creator': 0.4, 'create': 0.8},\n",
       " {'name': 1.43,\n",
       "  'spell': 0.24,\n",
       "  'correctly': 0.24,\n",
       "  'im': 0.26,\n",
       "  'call': 0.41,\n",
       "  'travel': 0.24,\n",
       "  'go': 0.27,\n",
       "  'pass': 0.2},\n",
       " {'need': 0.46,\n",
       "  'help': 0.86,\n",
       "  'support': 0.41,\n",
       "  'please': 0.49,\n",
       "  'could': 0.2,\n",
       "  'give': 0.24,\n",
       "  'hand': 0.24,\n",
       "  'assistance': 0.15},\n",
       " {'feel': 0.72,\n",
       "  'sad': 0.57,\n",
       "  'lonely': 0.48,\n",
       "  'dont': 0.22,\n",
       "  'well': 0.11,\n",
       "  'bad': 0.19,\n",
       "  'im': 0.07,\n",
       "  'anyone': 0.16,\n",
       "  'good': 0.11,\n",
       "  'empty': 0.19},\n",
       " {'stress': 1.46,\n",
       "  'feel': 0.35,\n",
       "  'im': 0.09,\n",
       "  'stick': 0.73,\n",
       "  'still': 0.49,\n",
       "  'burn': 0.24},\n",
       " {'cannot': 0.14,\n",
       "  'anything': 0.31,\n",
       "  'cant': 0.1,\n",
       "  'nothing': 0.24,\n",
       "  'make': 0.36,\n",
       "  'sense': 0.41,\n",
       "  'feel': 0.15,\n",
       "  'worthless': 0.32,\n",
       "  'unable': 0.14,\n",
       "  'anymore': 0.27,\n",
       "  'one': 0.32,\n",
       "  'like': 0.13,\n",
       "  'useless': 0.14,\n",
       "  'nobody': 0.14,\n",
       "  'enjoy': 0.16},\n",
       " {'cant': 0.22,\n",
       "  'take': 0.27,\n",
       "  'anymore': 0.31,\n",
       "  'im': 0.19,\n",
       "  'depress': 1.08,\n",
       "  'think': 0.22,\n",
       "  'tolerate': 0.18,\n",
       "  'longer': 0.18,\n",
       "  'depression': 0.25,\n",
       "  'believe': 0.15,\n",
       "  'suffer': 0.12},\n",
       " {'im': 0.27,\n",
       "  'good': 0.21,\n",
       "  'feel': 0.45,\n",
       "  'great': 0.39,\n",
       "  'today': 0.38,\n",
       "  'cheerful': 0.19,\n",
       "  'well': 0.11,\n",
       "  'happy': 0.57,\n",
       "  'ok': 0.13,\n",
       "  'fine': 0.16},\n",
       " {'k': 0.67,\n",
       "  'person': 0.23,\n",
       "  'ok': 0.23,\n",
       "  'okay': 0.34,\n",
       "  'fine': 0.28,\n",
       "  'whatever': 0.34,\n",
       "  'yeah': 0.28,\n",
       "  'oh': 0.34,\n",
       "  'see': 0.28,\n",
       "  'nice': 0.21,\n",
       "  'really': 0.28,\n",
       "  'yes': 0.25},\n",
       " {'nervous': 1.25, 'feel': 0.4, 'anxious': 1.04, 'im': 0.37, 'worry': 0.18},\n",
       " {'dont': 0.31,\n",
       "  'want': 0.22,\n",
       "  'talk': 0.21,\n",
       "  'stop': 0.14,\n",
       "  'discuss': 0.12,\n",
       "  'cant': 0.19,\n",
       "  'open': 0.32,\n",
       "  'bring': 0.16,\n",
       "  'stay': 0.55,\n",
       "  'away': 0.55,\n",
       "  'shut': 0.32},\n",
       " {'havent': 0.9,\n",
       "  'sleep': 1.12,\n",
       "  'long': 0.11,\n",
       "  'time': 0.11,\n",
       "  'last': 0.11,\n",
       "  'days': 0.45,\n",
       "  'proper': 0.11,\n",
       "  'past': 0.11,\n",
       "  'good': 0.12,\n",
       "  'nights': 0.22,\n",
       "  'cant': 0.13,\n",
       "  'suffer': 0.08,\n",
       "  'insomnia': 0.11,\n",
       "  'insominia': 0.11,\n",
       "  'well': 0.07,\n",
       "  'seem': 0.09,\n",
       "  'go': 0.06},\n",
       " {'scar': 0.73,\n",
       "  'afraid': 0.18,\n",
       "  'im': 0.19,\n",
       "  'dont': 0.21,\n",
       "  'want': 0.25,\n",
       "  'feel': 0.26,\n",
       "  'way': 0.55,\n",
       "  'sound': 0.31,\n",
       "  'awful': 0.18,\n",
       "  'terrible': 0.18},\n",
       " {'mom': 0.28,\n",
       "  'die': 0.71,\n",
       "  'dad': 0.28,\n",
       "  'pass': 0.71,\n",
       "  'away': 0.71,\n",
       "  'sister': 0.42,\n",
       "  'father': 0.14,\n",
       "  'friend': 0.14,\n",
       "  'someone': 0.09,\n",
       "  'family': 0.12,\n",
       "  'brother': 0.14,\n",
       "  'mother': 0.14},\n",
       " {'cant': 0.28,\n",
       "  'possibly': 0.12,\n",
       "  'know': 0.25,\n",
       "  'im': 0.17,\n",
       "  'go': 0.26,\n",
       "  'help': 0.21,\n",
       "  'dont': 0.09,\n",
       "  'youre': 0.27,\n",
       "  'robot': 0.24,\n",
       "  'would': 0.1,\n",
       "  'understand': 0.3,\n",
       "  'unable': 0.1,\n",
       "  'cannot': 0.1,\n",
       "  'nobody': 0.1,\n",
       "  'useless': 0.1},\n",
       " {'yes': 0.16,\n",
       "  'would': 0.27,\n",
       "  'thats': 0.53,\n",
       "  'nothing': 0.63,\n",
       "  'else': 0.53,\n",
       "  'say': 0.43,\n",
       "  'sight': 0.21,\n",
       "  'dont': 0.08,\n",
       "  'anything': 0.13},\n",
       " {'ive': 0.36,\n",
       "  'consider': 0.14,\n",
       "  'kill': 0.99,\n",
       "  'contemplate': 0.14,\n",
       "  'would': 0.18,\n",
       "  'love': 0.14,\n",
       "  'die': 0.36,\n",
       "  'think': 0.17,\n",
       "  'want': 0.13,\n",
       "  'commit': 0.28,\n",
       "  'suicide': 0.28,\n",
       "  'like': 0.12,\n",
       "  'go': 0.16},\n",
       " {'like': 0.36,\n",
       "  'much': 0.21,\n",
       "  'dont': 0.54,\n",
       "  'think': 0.31,\n",
       "  'right': 0.13,\n",
       "  'believe': 0.3,\n",
       "  'hate': 0.15,\n",
       "  'reliable': 0.18,\n",
       "  'trust': 0.18,\n",
       "  'trustworthy': 0.18},\n",
       " {'dont': 0.33, 'like': 0.48, 'know': 0.48, 'hate': 0.49, 'dislike': 0.58},\n",
       " {'relationship': 0.94,\n",
       "  'exams': 0.47,\n",
       "  'financial': 0.63,\n",
       "  'problems': 0.21,\n",
       "  'friends': 0.23,\n",
       "  'money': 0.31,\n",
       "  'boyfriend': 0.31,\n",
       "  'family': 0.26,\n",
       "  'issue': 0.2,\n",
       "  'girlfriend': 0.31},\n",
       " {'tell': 0.72,\n",
       "  'joke': 0.97,\n",
       "  'funny': 0.61,\n",
       "  'tale': 0.12,\n",
       "  'better': 0.1,\n",
       "  'another': 0.1,\n",
       "  'funnier': 0.12,\n",
       "  'need': 0.06,\n",
       "  'new': 0.31,\n",
       "  'let': 0.08,\n",
       "  'know': 0.05,\n",
       "  'story': 0.12,\n",
       "  'something': 0.06,\n",
       "  'anecdote': 0.12},\n",
       " {'keep': 0.16,\n",
       "  'repeat': 0.66,\n",
       "  'already': 1.53,\n",
       "  'tell': 0.26,\n",
       "  'mention': 1.31,\n",
       "  'say': 0.15},\n",
       " {'talk': 0.13,\n",
       "  'discuss': 0.15,\n",
       "  'wrong': 0.8,\n",
       "  'answer': 0.4,\n",
       "  'doesnt': 0.4,\n",
       "  'make': 0.6,\n",
       "  'sense': 0.67,\n",
       "  'mean': 0.14,\n",
       "  'response': 0.2,\n",
       "  'say': 0.14,\n",
       "  'reply': 0.2},\n",
       " {'smart': 0.55,\n",
       "  'stupid': 0.82,\n",
       "  'think': 0.16,\n",
       "  'dumb': 0.82,\n",
       "  'youre': 0.62,\n",
       "  'crazy': 0.55,\n",
       "  'insane': 0.55},\n",
       " {'location': 1.46,\n",
       "  'live': 0.97,\n",
       "  'whats': 0.33,\n",
       "  'anything': 0.31,\n",
       "  'present': 0.49,\n",
       "  'locate': 0.49},\n",
       " {'talk': 0.54,\n",
       "  'dont': 0.19,\n",
       "  'want': 0.33,\n",
       "  'discuss': 0.46,\n",
       "  'something': 0.32,\n",
       "  'else': 0.39,\n",
       "  'would': 0.05,\n",
       "  'like': 0.05,\n",
       "  'let': 0.17},\n",
       " {'many': 0.73, 'friends': 1.92, 'dont': 0.42},\n",
       " {'anything': 0.35,\n",
       "  'else': 0.17,\n",
       "  'ask': 1.37,\n",
       "  'possible': 0.53,\n",
       "  'question': 0.27,\n",
       "  'something': 0.43,\n",
       "  'inquire': 0.14},\n",
       " {'feel': 0.24,\n",
       "  'stress': 0.38,\n",
       "  'dont': 0.19,\n",
       "  'think': 0.3,\n",
       "  'prepare': 0.51,\n",
       "  'well': 0.27,\n",
       "  'enough': 0.24,\n",
       "  'exams': 0.38,\n",
       "  'ive': 0.14,\n",
       "  'im': 0.04,\n",
       "  'probably': 0.22,\n",
       "  'approach': 0.06,\n",
       "  'due': 0.06},\n",
       " {'think': 0.78,\n",
       "  'exams': 0.66,\n",
       "  'cant': 0.13,\n",
       "  'guess': 0.44,\n",
       "  'dont': 0.08,\n",
       "  'isnt': 0.18,\n",
       "  'really': 0.74,\n",
       "  'suppose': 0.18},\n",
       " {'ok': 0.09,\n",
       "  'sure': 0.1,\n",
       "  'would': 0.36,\n",
       "  'like': 0.4,\n",
       "  'learn': 0.62,\n",
       "  'want': 0.25,\n",
       "  'know': 0.28,\n",
       "  'yes': 0.1,\n",
       "  'id': 0.12},\n",
       " {'need': 0.13,\n",
       "  'take': 0.1,\n",
       "  'break': 0.82,\n",
       "  'get': 0.07,\n",
       "  'absolutely': 0.41,\n",
       "  'correct': 0.82,\n",
       "  'yeah': 0.23,\n",
       "  'youre': 0.62,\n",
       "  'right': 0.21,\n",
       "  'deserve': 0.41},\n",
       " {'sound': 1.04,\n",
       "  'like': 0.33,\n",
       "  'could': 0.57,\n",
       "  'useful': 1.04,\n",
       "  'seem': 0.09,\n",
       "  'hmmm': 0.11,\n",
       "  'would': 0.05,\n",
       "  'helpful': 0.09},\n",
       " {'im': 0.04,\n",
       "  'feel': 0.57,\n",
       "  'better': 1.01,\n",
       "  'thank': 0.33,\n",
       "  'much': 0.19,\n",
       "  'say': 0.37,\n",
       "  'alot': 0.11,\n",
       "  'lot': 0.18,\n",
       "  'tell': 0.13},\n",
       " {'thank': 0.06,\n",
       "  'much': 0.05,\n",
       "  'ill': 0.13,\n",
       "  'continue': 0.31,\n",
       "  'practice': 0.77,\n",
       "  'meditation': 0.77,\n",
       "  'focus': 0.92,\n",
       "  'control': 0.92,\n",
       "  'keep': 0.23,\n",
       "  'meditate': 0.08},\n",
       " {'would': 0.13,\n",
       "  'appreciate': 0.15,\n",
       "  'advice': 0.73,\n",
       "  'need': 0.62,\n",
       "  'help': 0.35,\n",
       "  'want': 0.07,\n",
       "  'something': 0.23,\n",
       "  'someone': 0.09,\n",
       "  'assistance': 0.28,\n",
       "  'like': 0.06},\n",
       " {'want': 0.11,\n",
       "  'know': 0.17,\n",
       "  'mental': 0.32,\n",
       "  'health': 0.4,\n",
       "  'need': 0.12,\n",
       "  'aware': 0.2,\n",
       "  'dont': 0.06,\n",
       "  'enough': 0.07,\n",
       "  'much': 0.05,\n",
       "  'issue': 0.1,\n",
       "  'would': 0.07,\n",
       "  'like': 0.07,\n",
       "  'learn': 0.24,\n",
       "  'im': 0.03,\n",
       "  'interest': 0.08},\n",
       " {'tell': 0.37,\n",
       "  'another': 0.08,\n",
       "  'fact': 0.18,\n",
       "  'mental': 0.35,\n",
       "  'health': 0.44,\n",
       "  'let': 0.12,\n",
       "  'know': 0.19,\n",
       "  'want': 0.04,\n",
       "  'something': 0.09,\n",
       "  'else': 0.06,\n",
       "  'need': 0.04,\n",
       "  'thing': 0.09,\n",
       "  'would': 0.04,\n",
       "  'like': 0.04},\n",
       " {'mental': 0.49,\n",
       "  'health': 0.62,\n",
       "  'something': 0.13,\n",
       "  'understand': 0.11,\n",
       "  'mean': 0.26,\n",
       "  'define': 0.42,\n",
       "  'purpose': 0.13},\n",
       " {'mental': 0.47,\n",
       "  'health': 0.59,\n",
       "  'matter': 0.39,\n",
       "  'important': 0.64,\n",
       "  'crucial': 0.13,\n",
       "  'mean': 0.09,\n",
       "  'significance': 0.11,\n",
       "  'importance': 0.13},\n",
       " {'define': 0.74, 'depression': 2.4},\n",
       " {'mentally': 0.73,\n",
       "  'ill': 0.61,\n",
       "  'suffer': 0.25,\n",
       "  'depression': 0.5,\n",
       "  'know': 0.15,\n",
       "  'wonder': 0.31,\n",
       "  'depress': 0.61,\n",
       "  'dont': 0.07,\n",
       "  'possible': 0.1},\n",
       " {'therapist': 2.55, 'suppose': 0.57, 'therapists': 0.67},\n",
       " {'therapy': 2.11,\n",
       "  'necessary': 0.42,\n",
       "  'receive': 0.21,\n",
       "  'require': 0.21,\n",
       "  'wonder': 0.35,\n",
       "  'need': 0.3},\n",
       " {'talk': 0.08,\n",
       "  'mental': 0.51,\n",
       "  'illness': 0.76,\n",
       "  'mean': 0.79,\n",
       "  'illnesses': 0.1,\n",
       "  'disorder': 0.11},\n",
       " {'people': 0.41,\n",
       "  'affect': 0.66,\n",
       "  'mental': 0.43,\n",
       "  'illness': 0.78,\n",
       "  'cause': 0.33,\n",
       "  'suffer': 0.07},\n",
       " {'cause': 0.76,\n",
       "  'mental': 0.4,\n",
       "  'illness': 0.6,\n",
       "  'top': 0.17,\n",
       "  'illnesses': 0.15,\n",
       "  'common': 0.41,\n",
       "  'main': 0.17,\n",
       "  'root': 0.1},\n",
       " {'sign': 1.04,\n",
       "  'mental': 0.41,\n",
       "  'illness': 0.74,\n",
       "  'warn': 0.52,\n",
       "  'symptoms': 0.18,\n",
       "  'telltale': 0.1},\n",
       " {'possible': 0.42,\n",
       "  'people': 0.38,\n",
       "  'mental': 0.33,\n",
       "  'illness': 0.35,\n",
       "  'recover': 0.67,\n",
       "  'illnesses': 0.32,\n",
       "  'chance': 0.08,\n",
       "  'get': 0.13,\n",
       "  'overcome': 0.08},\n",
       " {'know': 0.43,\n",
       "  'someone': 0.41,\n",
       "  'appear': 0.13,\n",
       "  'symptoms': 0.11,\n",
       "  'mental': 0.34,\n",
       "  'disorder': 0.87,\n",
       "  'person': 0.26},\n",
       " {'find': 0.32,\n",
       "  'mental': 0.31,\n",
       "  'health': 0.39,\n",
       "  'professional': 0.79,\n",
       "  'child': 0.46,\n",
       "  'im': 0.06,\n",
       "  'look': 0.06,\n",
       "  'need': 0.07,\n",
       "  'get': 0.04},\n",
       " {'treatment': 0.61,\n",
       "  'options': 1.14,\n",
       "  'available': 1.23,\n",
       "  'treatments': 0.49,\n",
       "  'ones': 0.16,\n",
       "  'choices': 0.16,\n",
       "  'currently': 0.16},\n",
       " {'dont': 0.03,\n",
       "  'know': 0.31,\n",
       "  'need': 0.31,\n",
       "  'involve': 0.99,\n",
       "  'treatment': 0.74,\n",
       "  'become': 0.25,\n",
       "  'get': 0.22,\n",
       "  'im': 0.03,\n",
       "  'sure': 0.12},\n",
       " {'differences': 0.35,\n",
       "  'mental': 0.37,\n",
       "  'health': 0.46,\n",
       "  'workers': 0.31,\n",
       "  'difference': 0.21,\n",
       "  'professionals': 0.63,\n",
       "  'different': 0.19},\n",
       " {'mental': 0.3,\n",
       "  'health': 0.38,\n",
       "  'professional': 0.78,\n",
       "  'child': 0.78,\n",
       "  'find': 0.27,\n",
       "  'right': 0.06,\n",
       "  'get': 0.08},\n",
       " {'find': 0.22, 'help': 0.65, 'get': 0.77, 'assistance': 0.46, 'else': 0.46},\n",
       " {'know': 0.32,\n",
       "  'start': 0.53,\n",
       "  'new': 0.98,\n",
       "  'medication': 1.07,\n",
       "  'aware': 0.33,\n",
       "  'drug': 0.1,\n",
       "  'take': 0.07},\n",
       " {'get': 0.43,\n",
       "  'therapy': 0.68,\n",
       "  'find': 0.48,\n",
       "  'help': 0.19,\n",
       "  'want': 0.15,\n",
       "  'therapist': 0.55,\n",
       "  'go': 0.27,\n",
       "  'assistance': 0.1},\n",
       " {'want': 0.06,\n",
       "  'learn': 0.21,\n",
       "  'mental': 0.27,\n",
       "  'health': 0.35,\n",
       "  'treatment': 0.63,\n",
       "  'would': 0.06,\n",
       "  'like': 0.06,\n",
       "  'type': 0.06,\n",
       "  'im': 0.05,\n",
       "  'look': 0.21,\n",
       "  'information': 0.42,\n",
       "  'know': 0.06,\n",
       "  'find': 0.08},\n",
       " {'different': 0.46,\n",
       "  'kinds': 0.15,\n",
       "  'mental': 0.29,\n",
       "  'health': 0.37,\n",
       "  'workers': 0.19,\n",
       "  'type': 0.5,\n",
       "  'professionals': 0.56,\n",
       "  'exist': 0.15,\n",
       "  'available': 0.06,\n",
       "  'kind': 0.07},\n",
       " {'want': 0.09,\n",
       "  'find': 0.41,\n",
       "  'support': 0.92,\n",
       "  'group': 1.1,\n",
       "  'im': 0.07,\n",
       "  'look': 0.22,\n",
       "  'would': 0.04,\n",
       "  'like': 0.08,\n",
       "  'id': 0.08,\n",
       "  'someone': 0.06,\n",
       "  'talk': 0.06,\n",
       "  'need': 0.05,\n",
       "  'go': 0.06},\n",
       " {'mental': 0.32,\n",
       "  'health': 0.4,\n",
       "  'issue': 0.31,\n",
       "  'prevent': 0.49,\n",
       "  'possible': 0.18,\n",
       "  'stop': 0.41,\n",
       "  'problems': 0.33,\n",
       "  'do': 0.14},\n",
       " {'cure': 1.14,\n",
       "  'mental': 0.38,\n",
       "  'health': 0.43,\n",
       "  'issue': 0.3,\n",
       "  'illness': 0.06,\n",
       "  'problems': 0.26,\n",
       "  'possible': 0.05},\n",
       " {'main': 0.14,\n",
       "  'cause': 0.67,\n",
       "  'mental': 0.32,\n",
       "  'health': 0.4,\n",
       "  'problems': 0.39,\n",
       "  'something': 0.13,\n",
       "  'top': 0.07,\n",
       "  'reason': 0.08,\n",
       "  'issue': 0.26},\n",
       " {'concern': 0.31, 'mental': 0.41, 'health': 0.52, 'im': 0.26, 'worry': 0.7},\n",
       " {'sure': 0.07,\n",
       "  'im': 0.42,\n",
       "  'well': 0.41,\n",
       "  'feel': 0.14,\n",
       "  'know': 0.37,\n",
       "  'possible': 0.22,\n",
       "  'sick': 0.2,\n",
       "  'dont': 0.04,\n",
       "  'tell': 0.12,\n",
       "  'unwell': 0.3},\n",
       " {'keep': 0.31,\n",
       "  'touch': 0.82,\n",
       "  'people': 0.15,\n",
       "  'stay': 0.34,\n",
       "  'friends': 0.46,\n",
       "  'do': 0.09,\n",
       "  'maintain': 0.41,\n",
       "  'social': 0.41,\n",
       "  'connections': 0.31,\n",
       "  'possible': 0.11,\n",
       "  'feel': 0.05,\n",
       "  'lonely': 0.09,\n",
       "  'would': 0.04,\n",
       "  'like': 0.04,\n",
       "  'network': 0.1},\n",
       " {'difference': 0.55,\n",
       "  'stress': 1.09,\n",
       "  'anxiety': 1.46,\n",
       "  'different': 0.17,\n",
       "  'whats': 0.17,\n",
       "  'differences': 0.18},\n",
       " {'differences': 0.18,\n",
       "  'sadness': 1.42,\n",
       "  'depression': 0.97,\n",
       "  'different': 0.24,\n",
       "  'difference': 0.53,\n",
       "  'things': 0.12,\n",
       "  'whats': 0.08}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Term Frequency for every sentence\n",
    "import math\n",
    "tfidf = []\n",
    "\n",
    "for word in texts['patterns'].unique():\n",
    "    v = {}\n",
    "    for i in word.split(\" \"):\n",
    "        if i in v.keys():\n",
    "            v[i] += 1\n",
    "        else:\n",
    "            v[i] = 1\n",
    "    tf = {k: val/len(word.split(\" \")) for k, val in v.items()}\n",
    "    idf = {k: math.log(len(texts)/sum([k in i.split(\" \") for i in texts['patterns'].unique()])) for k, val in v.items()}\n",
    "    tfidfx = {k: round(v*idf[k],2) for k, v in tf.items()}\n",
    "    tfidf.append(tfidfx)\n",
    "    print(\"\\n\")\n",
    "\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135e2e2",
   "metadata": {},
   "source": [
    "#### So, every sentence in our dataset will be of size (1 x 330) and our TF-IDF vectorization will be of size (80 x 1 x 330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4079453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1, 330)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_size = np.zeros((len(texts), 1, len(vocabs)))\n",
    "tfidf_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a14f1420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anyone': 0.28, 'ola': 0.34, 'hey': 0.67, 'hi': 0.67, 'howdy': 0.34, 'konnichiwa': 0.34, 'guten': 0.34, 'tag': 0.34, 'hola': 0.34, 'bonjour': 0.34, 'hello': 0.34}\n",
      "{'great': 0.28, 'wake': 0.27, 'good': 0.38, 'start': 0.84, 'day': 0.75, 'warm': 0.14, 'nice': 0.26, 'morning': 0.1}\n",
      "{'nice': 0.43, 'day': 0.81, 'good': 0.75, 'start': 0.35, 'afternoon': 0.17, 'morning': 0.38}\n",
      "{'nice': 0.32, 'day': 0.46, 'morning': 0.38, 'good': 0.75, 'night': 0.57, 'start': 0.23, 'even': 0.14, 'great': 0.12}\n",
      "{'good': 0.42, 'even': 0.64, 'night': 0.8, 'nice': 0.48, 'day': 0.26, 'wonderful': 0.19, 'great': 0.39}\n",
      "{'goodbye': 0.77, 'ok': 0.18, 'bye': 1.03, 'fare': 0.26, 'thee': 0.26, 'well': 0.15, 'alright': 0.26, 'see': 0.22, 'later': 0.26, 'sayonara': 0.26, 'au': 0.26, 'revoir': 0.26}\n",
      "{'thats': 0.39, 'helpful': 0.39, 'thank': 1.21, 'much': 0.55, 'help': 0.27, 'assistance': 0.15, 'useful': 0.19}\n",
      "{'person': 0.27, 'someone': 0.5, 'rain': 0.4, 'n': 0.4, 'vvvvvvvvvvvvv': 0.4, 'theres': 0.4, 'something': 0.21, 'indeed': 0.4, 'xcaxxczcq': 0.4, 'mbndjjfjfjsssf': 0.4}\n",
      "{'nothing': 0.69, 'significant': 1.38, 'much': 0.41, 'isnt': 0.19, 'significance': 0.39, 'wasnt': 0.23, 'anything': 0.15, 'lot': 0.19}\n",
      "{'whats': 0.27, 'name': 1.01, 'tell': 0.71, 'let': 0.27, 'know': 0.17, 'call': 0.34, 'person': 0.27}\n",
      "{'plan': 2.19, 'go': 0.61, 'able': 1.1}\n",
      "{'get': 0.42, 'arrive': 0.4, 'make': 1.49, 'creator': 0.4, 'create': 0.8}\n",
      "{'name': 1.43, 'spell': 0.24, 'correctly': 0.24, 'im': 0.26, 'call': 0.41, 'travel': 0.24, 'go': 0.27, 'pass': 0.2}\n",
      "{'need': 0.46, 'help': 0.86, 'support': 0.41, 'please': 0.49, 'could': 0.2, 'give': 0.24, 'hand': 0.24, 'assistance': 0.15}\n",
      "{'feel': 0.72, 'sad': 0.57, 'lonely': 0.48, 'dont': 0.22, 'well': 0.11, 'bad': 0.19, 'im': 0.07, 'anyone': 0.16, 'good': 0.11, 'empty': 0.19}\n",
      "{'stress': 1.46, 'feel': 0.35, 'im': 0.09, 'stick': 0.73, 'still': 0.49, 'burn': 0.24}\n",
      "{'cannot': 0.14, 'anything': 0.31, 'cant': 0.1, 'nothing': 0.24, 'make': 0.36, 'sense': 0.41, 'feel': 0.15, 'worthless': 0.32, 'unable': 0.14, 'anymore': 0.27, 'one': 0.32, 'like': 0.13, 'useless': 0.14, 'nobody': 0.14, 'enjoy': 0.16}\n",
      "{'cant': 0.22, 'take': 0.27, 'anymore': 0.31, 'im': 0.19, 'depress': 1.08, 'think': 0.22, 'tolerate': 0.18, 'longer': 0.18, 'depression': 0.25, 'believe': 0.15, 'suffer': 0.12}\n",
      "{'im': 0.27, 'good': 0.21, 'feel': 0.45, 'great': 0.39, 'today': 0.38, 'cheerful': 0.19, 'well': 0.11, 'happy': 0.57, 'ok': 0.13, 'fine': 0.16}\n",
      "{'k': 0.67, 'person': 0.23, 'ok': 0.23, 'okay': 0.34, 'fine': 0.28, 'whatever': 0.34, 'yeah': 0.28, 'oh': 0.34, 'see': 0.28, 'nice': 0.21, 'really': 0.28, 'yes': 0.25}\n",
      "{'nervous': 1.25, 'feel': 0.4, 'anxious': 1.04, 'im': 0.37, 'worry': 0.18}\n",
      "{'dont': 0.31, 'want': 0.22, 'talk': 0.21, 'stop': 0.14, 'discuss': 0.12, 'cant': 0.19, 'open': 0.32, 'bring': 0.16, 'stay': 0.55, 'away': 0.55, 'shut': 0.32}\n",
      "{'havent': 0.9, 'sleep': 1.12, 'long': 0.11, 'time': 0.11, 'last': 0.11, 'days': 0.45, 'proper': 0.11, 'past': 0.11, 'good': 0.12, 'nights': 0.22, 'cant': 0.13, 'suffer': 0.08, 'insomnia': 0.11, 'insominia': 0.11, 'well': 0.07, 'seem': 0.09, 'go': 0.06}\n",
      "{'scar': 0.73, 'afraid': 0.18, 'im': 0.19, 'dont': 0.21, 'want': 0.25, 'feel': 0.26, 'way': 0.55, 'sound': 0.31, 'awful': 0.18, 'terrible': 0.18}\n",
      "{'mom': 0.28, 'die': 0.71, 'dad': 0.28, 'pass': 0.71, 'away': 0.71, 'sister': 0.42, 'father': 0.14, 'friend': 0.14, 'someone': 0.09, 'family': 0.12, 'brother': 0.14, 'mother': 0.14}\n",
      "{'cant': 0.28, 'possibly': 0.12, 'know': 0.25, 'im': 0.17, 'go': 0.26, 'help': 0.21, 'dont': 0.09, 'youre': 0.27, 'robot': 0.24, 'would': 0.1, 'understand': 0.3, 'unable': 0.1, 'cannot': 0.1, 'nobody': 0.1, 'useless': 0.1}\n",
      "{'yes': 0.16, 'would': 0.27, 'thats': 0.53, 'nothing': 0.63, 'else': 0.53, 'say': 0.43, 'sight': 0.21, 'dont': 0.08, 'anything': 0.13}\n",
      "{'ive': 0.36, 'consider': 0.14, 'kill': 0.99, 'contemplate': 0.14, 'would': 0.18, 'love': 0.14, 'die': 0.36, 'think': 0.17, 'want': 0.13, 'commit': 0.28, 'suicide': 0.28, 'like': 0.12, 'go': 0.16}\n",
      "{'like': 0.36, 'much': 0.21, 'dont': 0.54, 'think': 0.31, 'right': 0.13, 'believe': 0.3, 'hate': 0.15, 'reliable': 0.18, 'trust': 0.18, 'trustworthy': 0.18}\n",
      "{'dont': 0.33, 'like': 0.48, 'know': 0.48, 'hate': 0.49, 'dislike': 0.58}\n",
      "{'relationship': 0.94, 'exams': 0.47, 'financial': 0.63, 'problems': 0.21, 'friends': 0.23, 'money': 0.31, 'boyfriend': 0.31, 'family': 0.26, 'issue': 0.2, 'girlfriend': 0.31}\n",
      "{'tell': 0.72, 'joke': 0.97, 'funny': 0.61, 'tale': 0.12, 'better': 0.1, 'another': 0.1, 'funnier': 0.12, 'need': 0.06, 'new': 0.31, 'let': 0.08, 'know': 0.05, 'story': 0.12, 'something': 0.06, 'anecdote': 0.12}\n",
      "{'keep': 0.16, 'repeat': 0.66, 'already': 1.53, 'tell': 0.26, 'mention': 1.31, 'say': 0.15}\n",
      "{'talk': 0.13, 'discuss': 0.15, 'wrong': 0.8, 'answer': 0.4, 'doesnt': 0.4, 'make': 0.6, 'sense': 0.67, 'mean': 0.14, 'response': 0.2, 'say': 0.14, 'reply': 0.2}\n",
      "{'smart': 0.55, 'stupid': 0.82, 'think': 0.16, 'dumb': 0.82, 'youre': 0.62, 'crazy': 0.55, 'insane': 0.55}\n",
      "{'location': 1.46, 'live': 0.97, 'whats': 0.33, 'anything': 0.31, 'present': 0.49, 'locate': 0.49}\n",
      "{'talk': 0.54, 'dont': 0.19, 'want': 0.33, 'discuss': 0.46, 'something': 0.32, 'else': 0.39, 'would': 0.05, 'like': 0.05, 'let': 0.17}\n",
      "{'many': 0.73, 'friends': 1.92, 'dont': 0.42}\n",
      "{'anything': 0.35, 'else': 0.17, 'ask': 1.37, 'possible': 0.53, 'question': 0.27, 'something': 0.43, 'inquire': 0.14}\n",
      "{'feel': 0.24, 'stress': 0.38, 'dont': 0.19, 'think': 0.3, 'prepare': 0.51, 'well': 0.27, 'enough': 0.24, 'exams': 0.38, 'ive': 0.14, 'im': 0.04, 'probably': 0.22, 'approach': 0.06, 'due': 0.06}\n",
      "{'think': 0.78, 'exams': 0.66, 'cant': 0.13, 'guess': 0.44, 'dont': 0.08, 'isnt': 0.18, 'really': 0.74, 'suppose': 0.18}\n",
      "{'ok': 0.09, 'sure': 0.1, 'would': 0.36, 'like': 0.4, 'learn': 0.62, 'want': 0.25, 'know': 0.28, 'yes': 0.1, 'id': 0.12}\n",
      "{'need': 0.13, 'take': 0.1, 'break': 0.82, 'get': 0.07, 'absolutely': 0.41, 'correct': 0.82, 'yeah': 0.23, 'youre': 0.62, 'right': 0.21, 'deserve': 0.41}\n",
      "{'sound': 1.04, 'like': 0.33, 'could': 0.57, 'useful': 1.04, 'seem': 0.09, 'hmmm': 0.11, 'would': 0.05, 'helpful': 0.09}\n",
      "{'im': 0.04, 'feel': 0.57, 'better': 1.01, 'thank': 0.33, 'much': 0.19, 'say': 0.37, 'alot': 0.11, 'lot': 0.18, 'tell': 0.13}\n",
      "{'thank': 0.06, 'much': 0.05, 'ill': 0.13, 'continue': 0.31, 'practice': 0.77, 'meditation': 0.77, 'focus': 0.92, 'control': 0.92, 'keep': 0.23, 'meditate': 0.08}\n",
      "{'would': 0.13, 'appreciate': 0.15, 'advice': 0.73, 'need': 0.62, 'help': 0.35, 'want': 0.07, 'something': 0.23, 'someone': 0.09, 'assistance': 0.28, 'like': 0.06}\n",
      "{'want': 0.11, 'know': 0.17, 'mental': 0.32, 'health': 0.4, 'need': 0.12, 'aware': 0.2, 'dont': 0.06, 'enough': 0.07, 'much': 0.05, 'issue': 0.1, 'would': 0.07, 'like': 0.07, 'learn': 0.24, 'im': 0.03, 'interest': 0.08}\n",
      "{'tell': 0.37, 'another': 0.08, 'fact': 0.18, 'mental': 0.35, 'health': 0.44, 'let': 0.12, 'know': 0.19, 'want': 0.04, 'something': 0.09, 'else': 0.06, 'need': 0.04, 'thing': 0.09, 'would': 0.04, 'like': 0.04}\n",
      "{'mental': 0.49, 'health': 0.62, 'something': 0.13, 'understand': 0.11, 'mean': 0.26, 'define': 0.42, 'purpose': 0.13}\n",
      "{'mental': 0.47, 'health': 0.59, 'matter': 0.39, 'important': 0.64, 'crucial': 0.13, 'mean': 0.09, 'significance': 0.11, 'importance': 0.13}\n",
      "{'define': 0.74, 'depression': 2.4}\n",
      "{'mentally': 0.73, 'ill': 0.61, 'suffer': 0.25, 'depression': 0.5, 'know': 0.15, 'wonder': 0.31, 'depress': 0.61, 'dont': 0.07, 'possible': 0.1}\n",
      "{'therapist': 2.55, 'suppose': 0.57, 'therapists': 0.67}\n",
      "{'therapy': 2.11, 'necessary': 0.42, 'receive': 0.21, 'require': 0.21, 'wonder': 0.35, 'need': 0.3}\n",
      "{'talk': 0.08, 'mental': 0.51, 'illness': 0.76, 'mean': 0.79, 'illnesses': 0.1, 'disorder': 0.11}\n",
      "{'people': 0.41, 'affect': 0.66, 'mental': 0.43, 'illness': 0.78, 'cause': 0.33, 'suffer': 0.07}\n",
      "{'cause': 0.76, 'mental': 0.4, 'illness': 0.6, 'top': 0.17, 'illnesses': 0.15, 'common': 0.41, 'main': 0.17, 'root': 0.1}\n",
      "{'sign': 1.04, 'mental': 0.41, 'illness': 0.74, 'warn': 0.52, 'symptoms': 0.18, 'telltale': 0.1}\n",
      "{'possible': 0.42, 'people': 0.38, 'mental': 0.33, 'illness': 0.35, 'recover': 0.67, 'illnesses': 0.32, 'chance': 0.08, 'get': 0.13, 'overcome': 0.08}\n",
      "{'know': 0.43, 'someone': 0.41, 'appear': 0.13, 'symptoms': 0.11, 'mental': 0.34, 'disorder': 0.87, 'person': 0.26}\n",
      "{'find': 0.32, 'mental': 0.31, 'health': 0.39, 'professional': 0.79, 'child': 0.46, 'im': 0.06, 'look': 0.06, 'need': 0.07, 'get': 0.04}\n",
      "{'treatment': 0.61, 'options': 1.14, 'available': 1.23, 'treatments': 0.49, 'ones': 0.16, 'choices': 0.16, 'currently': 0.16}\n",
      "{'dont': 0.03, 'know': 0.31, 'need': 0.31, 'involve': 0.99, 'treatment': 0.74, 'become': 0.25, 'get': 0.22, 'im': 0.03, 'sure': 0.12}\n",
      "{'differences': 0.35, 'mental': 0.37, 'health': 0.46, 'workers': 0.31, 'difference': 0.21, 'professionals': 0.63, 'different': 0.19}\n",
      "{'mental': 0.3, 'health': 0.38, 'professional': 0.78, 'child': 0.78, 'find': 0.27, 'right': 0.06, 'get': 0.08}\n",
      "{'find': 0.22, 'help': 0.65, 'get': 0.77, 'assistance': 0.46, 'else': 0.46}\n",
      "{'know': 0.32, 'start': 0.53, 'new': 0.98, 'medication': 1.07, 'aware': 0.33, 'drug': 0.1, 'take': 0.07}\n",
      "{'get': 0.43, 'therapy': 0.68, 'find': 0.48, 'help': 0.19, 'want': 0.15, 'therapist': 0.55, 'go': 0.27, 'assistance': 0.1}\n",
      "{'want': 0.06, 'learn': 0.21, 'mental': 0.27, 'health': 0.35, 'treatment': 0.63, 'would': 0.06, 'like': 0.06, 'type': 0.06, 'im': 0.05, 'look': 0.21, 'information': 0.42, 'know': 0.06, 'find': 0.08}\n",
      "{'different': 0.46, 'kinds': 0.15, 'mental': 0.29, 'health': 0.37, 'workers': 0.19, 'type': 0.5, 'professionals': 0.56, 'exist': 0.15, 'available': 0.06, 'kind': 0.07}\n",
      "{'want': 0.09, 'find': 0.41, 'support': 0.92, 'group': 1.1, 'im': 0.07, 'look': 0.22, 'would': 0.04, 'like': 0.08, 'id': 0.08, 'someone': 0.06, 'talk': 0.06, 'need': 0.05, 'go': 0.06}\n",
      "{'mental': 0.32, 'health': 0.4, 'issue': 0.31, 'prevent': 0.49, 'possible': 0.18, 'stop': 0.41, 'problems': 0.33, 'do': 0.14}\n",
      "{'cure': 1.14, 'mental': 0.38, 'health': 0.43, 'issue': 0.3, 'illness': 0.06, 'problems': 0.26, 'possible': 0.05}\n",
      "{'main': 0.14, 'cause': 0.67, 'mental': 0.32, 'health': 0.4, 'problems': 0.39, 'something': 0.13, 'top': 0.07, 'reason': 0.08, 'issue': 0.26}\n",
      "{'concern': 0.31, 'mental': 0.41, 'health': 0.52, 'im': 0.26, 'worry': 0.7}\n",
      "{'sure': 0.07, 'im': 0.42, 'well': 0.41, 'feel': 0.14, 'know': 0.37, 'possible': 0.22, 'sick': 0.2, 'dont': 0.04, 'tell': 0.12, 'unwell': 0.3}\n",
      "{'keep': 0.31, 'touch': 0.82, 'people': 0.15, 'stay': 0.34, 'friends': 0.46, 'do': 0.09, 'maintain': 0.41, 'social': 0.41, 'connections': 0.31, 'possible': 0.11, 'feel': 0.05, 'lonely': 0.09, 'would': 0.04, 'like': 0.04, 'network': 0.1}\n",
      "{'difference': 0.55, 'stress': 1.09, 'anxiety': 1.46, 'different': 0.17, 'whats': 0.17, 'differences': 0.18}\n",
      "{'differences': 0.18, 'sadness': 1.42, 'depression': 0.97, 'different': 0.24, 'difference': 0.53, 'things': 0.12, 'whats': 0.08}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]]], shape=(80, 1, 330))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 0\n",
    "for i in texts['patterns'].unique():\n",
    "    word_dict = tfidf[ind]\n",
    "    print(word_dict)\n",
    "    for k, v in word_dict.items():\n",
    "        vocab_index = vocab.index(k)\n",
    "        tfidf_value = v\n",
    "        tfidf_size[ind][0][vocab_index] = tfidf_value\n",
    "\n",
    "    ind += 1\n",
    "\n",
    "tfidf_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e266397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.75,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.38, 0.  ,\n",
       "        0.28, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.84, 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.27, 0.  , 0.14, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_size[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07f72966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'great': 0.28,\n",
       " 'wake': 0.27,\n",
       " 'good': 0.38,\n",
       " 'start': 0.84,\n",
       " 'day': 0.75,\n",
       " 'warm': 0.14,\n",
       " 'nice': 0.26,\n",
       " 'morning': 0.1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09d0017",
   "metadata": {},
   "source": [
    "## So, we are now done with TF-IDF\n",
    "\n",
    "However, it is still sparse and doesn't carry contextual or positional relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9790d3f",
   "metadata": {},
   "source": [
    "### Everything defined above is done using unigrams tokens/words. These can be performed using Bi-grams, Tri-grams or n-grams as well\n",
    "\n",
    "# TF-IDF using sklearn with n-gram: 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61cfa9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 1930 stored elements and shape (80, 1403)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = texts['patterns'].unique()\n",
    "\n",
    "tfv = TfidfVectorizer(ngram_range=(1, 2))\n",
    "vect = tfv.fit_transform(corpus)\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8a33115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['able', 'absolutely', 'absolutely correct', ..., 'youre robot',\n",
       "       'youre stupid', 'youre useless'], shape=(1403,), dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9575510f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1403)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1eb3f62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutely correct</th>\n",
       "      <th>absolutely right</th>\n",
       "      <th>advice</th>\n",
       "      <th>advice need</th>\n",
       "      <th>advice something</th>\n",
       "      <th>affect</th>\n",
       "      <th>affect affect</th>\n",
       "      <th>affect mental</th>\n",
       "      <th>...</th>\n",
       "      <th>yes would</th>\n",
       "      <th>youre</th>\n",
       "      <th>youre absolutely</th>\n",
       "      <th>youre correct</th>\n",
       "      <th>youre crazy</th>\n",
       "      <th>youre insane</th>\n",
       "      <th>youre right</th>\n",
       "      <th>youre robot</th>\n",
       "      <th>youre stupid</th>\n",
       "      <th>youre useless</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  absolutely correct  absolutely right  advice  \\\n",
       "0   0.0         0.0                 0.0               0.0     0.0   \n",
       "1   0.0         0.0                 0.0               0.0     0.0   \n",
       "2   0.0         0.0                 0.0               0.0     0.0   \n",
       "3   0.0         0.0                 0.0               0.0     0.0   \n",
       "4   0.0         0.0                 0.0               0.0     0.0   \n",
       "\n",
       "   advice need  advice something  affect  affect affect  affect mental  ...  \\\n",
       "0          0.0               0.0     0.0            0.0            0.0  ...   \n",
       "1          0.0               0.0     0.0            0.0            0.0  ...   \n",
       "2          0.0               0.0     0.0            0.0            0.0  ...   \n",
       "3          0.0               0.0     0.0            0.0            0.0  ...   \n",
       "4          0.0               0.0     0.0            0.0            0.0  ...   \n",
       "\n",
       "   yes would  youre  youre absolutely  youre correct  youre crazy  \\\n",
       "0        0.0    0.0               0.0            0.0          0.0   \n",
       "1        0.0    0.0               0.0            0.0          0.0   \n",
       "2        0.0    0.0               0.0            0.0          0.0   \n",
       "3        0.0    0.0               0.0            0.0          0.0   \n",
       "4        0.0    0.0               0.0            0.0          0.0   \n",
       "\n",
       "   youre insane  youre right  youre robot  youre stupid  youre useless  \n",
       "0           0.0          0.0          0.0           0.0            0.0  \n",
       "1           0.0          0.0          0.0           0.0            0.0  \n",
       "2           0.0          0.0          0.0           0.0            0.0  \n",
       "3           0.0          0.0          0.0           0.0            0.0  \n",
       "4           0.0          0.0          0.0           0.0            0.0  \n",
       "\n",
       "[5 rows x 1403 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vect[:5].toarray(), columns=tfv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3cb350",
   "metadata": {},
   "source": [
    "### We are now done with basic word vectorization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silvercule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
